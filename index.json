{
  "articles/Documentation/NetSDK-Repo-Tasks-Module.html": {
    "href": "articles/Documentation/NetSDK-Repo-Tasks-Module.html",
    "title": "Repo-Tasks Module | Azure SDK for Net",
    "keywords": "Repo-Tasks Module Usage: Start ./tools/PS-VSPrompt.lnk (shortcut), this will start VS Dev Prompt in powershell Import-Module ./tools/Repo-Tasks.psm1 During import, we allow to load additional functions that users might want to use it in their session. If you have any userPreference.ps1 file under %userprofile%/psFiles directory, the module will try to load it by dot sourcing it. It will also honor environment variable $env:psuserpreferences and load .ps1 files from the location that is pointed by $env:psuserpreferences As long as you have exported all the functions that you need from your ps1 file using export-modulemember -function . We deliberately do this to avoid polluting list of commands available (when you use Get-Command) Currently Repo-Tasks module supports following tasks: Set-TestEnvironment Will allow you create a test connection string required to setup test environment in order to run tests. More information about Test environment can be found here Start-Build Will allow you to kick off full build Or will allow you build for a particular scope (e.g. Start-Build -BuildScope ResourceManagment\\Compute) Get-BuildScopes Will allow you to query and find existing build scopes that can be used to build. Invoke-CheckinTests Will build and run existing tests. Install-VSProjectTemplates Installs projects templates for creating an empty project for AutoRest-SDK Project SDK for NET test project ###Note: If you do not start your powershell session using PS-VSPrompt shortcut, you will not have access to all the environment variables that are set as part of VS Dev Command prompt."
  },
  "articles/Documentation/ExistingManagementSDKVersioning.html": {
    "href": "articles/Documentation/ExistingManagementSDKVersioning.html",
    "title": "Versioning Rules followed for management plane | Azure SDK for Net",
    "keywords": "Versioning Rules followed for management plane For the sake of discussing this, let's assume we have a new RP (ContosoService) and is about to release it's first API version 2017-12-01-preview ResourceProvider Name: ContosoService API Version: 2017-12-01-preview When you publish your REST spec for Constoso, you will create your first .NET SDK with following versions Nuget publish date ==> Jan 01 2018 Nuget Package version ==> 0.9.0-preview AssemblyVersion ==> 0.9.0.0 AssemblyFileVersion ==> 0.9.0.0 Soon after you got feed back from your customers on your preview SDK and now you have few bugs to fix. So you iterated and published 2 additional SDK versions, for e.g. Preview 1 Nuget package version ==> 0.10.0-preview Assembly version ==> 0.10.0.0 Assembly Fileversion ==> 0.10.0.0 Publish date ==> Feb 01 2018 Preview 2 Nuget package version ==> 0.11.0-preview Assembly version ==> 0.11.0.0 Assembly Fileversion ==> 0.11.0.0 Publish date ==> Mar 01 2018 Stable Now you are ready to go stable and do the following: Publish your REST spec as stable (non-preview) as 2017-12-01 Nuget package version ==> 1.0.0 Assembly version ==> 1.0.0 Assembly Fileversion ==> 1.0.0 Publish date ==> Apr 01 2018 Now you are ready to add new feature to your stable version. Nuget package version ==> 1.1.0 Assembly version ==> 1.0.0 Assembly Fileversion ==> 1.1.0 Publish date ==> May 01 2018 Now you are ready to work on your new API version 2018-06-01-preview Preview 1 Nuget package version ==> 1.9.0-preview Assembly version ==> 1.9.0.0 Assembly Fileversion ==> 1.9.0.0 Publish date ==> Jul 01 2018 Preview 2 Nuget package version ==> 1.10.0-preview Assembly version ==> 1.10.0.0 Assembly Fileversion ==> 1.10.0.0 Publish date ==> Jul 01 2018 Now are your ready to go stable for 2018-06-01 Nuget package version ==> 2.0.0 Assembly version ==> 2.0.0.0 Assembly Fileversion ==> 2.0.0.0 Publish date ==> Aug 01 2018 If you ever have to add a new feature or fix a bug for your 1.0.0 stable SDK You can use the version range between 1.1.xx - 1.8.xx"
  },
  "articles/Documentation/code-generation-instructions.html": {
    "href": "articles/Documentation/code-generation-instructions.html",
    "title": "How to generate Code | Azure SDK for Net",
    "keywords": "How to generate Code To generate code, simply run the generate.ps1 powershell script. If code generation fails for any reason, here are a few common steps to resolve the issues. Clean the repo git clean -xdf Download and install the latest build tools (use a VS 2017 developer prompt to run msbuild) msbuild build.proj Run the generate.ps1 command again Powershell code generation script When the build tools are installed, AutoRest code generation commandlets are also installed on the user machine under the current user profile. If a powershell script does not exist under the RP directory, create one using the script generation utility script here An example usage is as below tools\\HelperUtilities\\psScripts\\Create-AutoRestCodeGenerationScript.ps1 -ResourceProvider compute/resource-manager -ScriptPath \"src\\SDKs\\Compute\\Management.Compute\\\" The generation script can also be manually created using an example here . Please make sure that the --output-folder setting is set in the configuration file for the RP. This path should be relative to src\\SDKs . For example, the --output-folder in configuration file for Compute is to $(csharp-sdks-folder)/Compute/Management.Compute/Generated The code generation script defaults csharp-sdks-folder to src\\SDKs . If for some reason this is incorrectly set, one can explicitly set the final location where code is generated using SdkGenerationDirectory parameter. This is discouraged though. When using the SdkGenerationDirectory parameter the generate.ps1 code would look like Start-AutoRestCodeGeneration -ResourceProvider \"compute/resource-manager\" -AutoRestVersion \"latest\" SdkGenerationDirectory \"$PSScriptRoot\" When opening a PR General instructions Please link the REST spec API PR which helps the review process Please check whether a new API version is introduced in the REST spec repo; this is important while addressing the instructions below Please read the SLA information and other instructions on the PR template before opening the PR REST API version artifacts If there is a new version of the REST API from which code is being generated for the PR, the following files should be modified/created in the PR A .props file which holds information about the REST API versions eg: here A SdkInfo_*.cs file which holds information about the REST API versions eg: here To generate the .props artifact, please run (use the VS 2017 developer prompt for msbuild): msbuild build.proj /t:build /p:Scope=SDKs\\<RP> RP is the resource provider's directory under SDKs, eg.: Compute To generate the SdkInfo*.cs file, please run the generate.ps1 script Code generation artifacts If code is generated using generate.ps1 , information related to the code generation gets logged in a .txt file under src\\SDKs\\_metadata eg.: here Please check the branch and fork of the REST spec for which the code was generated, this must always be Azure and master respectively for a PR to be valid. Code generated using specifications not checked in the Azure master branch will not be merged. How to sign/publish bits For detailed information about publishing and the overall workflow towards developing a powershell cli, click here How to generate code from a different fork and branch For testing purposes, code can be generated from any fork and branch. To do so, modify the generate.ps1 as below Start-AutoRestCodeGeneration -ResourceProvider \"<resourceprovider>\" -AutoRestVersion \"latest\" -SpecsRepoFork \"<forkname>\" -SpecsRepoBranch \"<branchname>\" If the spec is in a completely different repo, add the following argument to the command above -SpecsRepoName \"<specsrepo>\" We can also generate an sdk from a spec on a local path. Start-AutoRestCodeGenerationWithLocalConfig -ResourceProvider \"<resourceprovider>\" -AutoRestVersion \"latest\" -LocalConfigFilePath \"<path_to_config_file>\" Please note that the code generated from a spec on the local disk will not be accepted in the PRs against azure-sdk-for-net repo, this is for testing purposes only. The StartAutoRestCodeGeneration and Start-AutoRestCodeGenerationWithLocalConfig also expose a number of other useful parameters that can be checked by running Get-Help StartAutoRestCodeGeneration Get-Help Start-AutoRestCodeGenerationWithLocalConfig"
  },
  "articles/Documentation/breaking-changes.html": {
    "href": "articles/Documentation/breaking-changes.html",
    "title": "Breaking Change Definition | Azure SDK for Net",
    "keywords": "Breaking Change Definition Breaking changes in Azure SDK for .NET are defined as follows: Generated classes The class is removed The class is renamed The class no longer extends another class Properties of a generated class A property is removed A property is renamed A property has its type changed Methods of a generated class Methods should not be removed Methods should not be renamed Methods should not have their return type changed Parameters of methods in a generated class Parameters should not be removed Parameters should not have their type changed Parameters should preserve their ordering, including when a parameter is added Parameters should keep their default value, if they are assigned one"
  },
  "articles/Documentation/AuthConflictsBetweenSDKs.html": {
    "href": "articles/Documentation/AuthConflictsBetweenSDKs.html",
    "title": "Bridging gap between old and new SDKs | Azure SDK for Net",
    "keywords": "Bridging gap between old and new SDKs Authentication conflicts can happen due to mixing old SDKs* and new SDKs*. SDKs that depend on The credential types created by the new authentication library (Microsoft.Rest.ClientRuntime.Azure.Authentication, type = ServiceClientCredentials) are incompatible with the credential types used in older SDKs (Microsoft.Azure.Common, type = SubscriptionCloudCredentials). The problem is that using two different authentication libraries will require you to authenticate twice, which is a painful experience. Recommended solution To bridge this gap, the following adapter allows you to use the new credentials with clients that require the older credential type. Hereâ€™s the code for adapter public class SubscriptionCredentialsAdapter : SubscriptionCloudCredentials { ServiceClientCredentials _credentials; string _subscriptionId; public SubscriptionCredentialsAdapter(ServiceClientCredentials wrapped, string subscriptionId) { _credentials = wrapped; _subscriptionId = subscriptionId; } public override string SubscriptionId { get { return _subscriptionId; } } public override Task ProcessHttpRequestAsync(HttpRequestMessage request, CancellationToken cancellationToken) { return _credentials.ProcessHttpRequestAsync(request, cancellationToken); } } Here is how you can use the adapter var creds = UserTokenProvider.LoginWithPromptAsync(new ActiveDirectoryClientSettings(ClientId, new Uri(RedirectUri))).GetAwaiter().GetResult(); var subClient = new SubscriptionClient(creds); var subscriptions = subClient.Subscriptions.List(); var insightClient = new HDInsightManagementClient(new SubscriptionCredentialsAdapter(creds, subscriptions.First().SubscriptionId)); var clusters = insightClient.Clusters.List(); Another solution would be to use the version of resource manager library that is based on Microsoft.Azure.Common. It can be found here . Old SDKs - The SDKs that depend on Microsoft.Azure.Common New SDKs - The SDKs that depend on Microsoft.Rest.ClientRuntime.Azure"
  },
  "articles/README.html": {
    "href": "articles/README.html",
    "title": "Azure SDK for .NET | Azure SDK for Net",
    "keywords": "Azure SDK for .NET This repository contains official .NET libraries for Azure services. You can find NuGet packages for these libraries here . Getting started To get started with a library, see the README.md file located in the library's project folder. You can find these library folders grouped by service in the /sdk directory. For tutorials, samples, quick starts, and other documentation, go to Azure for .NET Developers . Packages available Each service might have a number of libraries available from each of the following categories discussed below: Client - July 2019 Preview Client - Stable Management Client: July 2019 Preview New wave of packages that we are currently releasing in preview . These libraries follow the Azure SDK Design Guidelines for .NET and share a number of core features such as HTTP retries, logging, transport protocols, authentication protocols, etc., so that once you learn how to use these features in one client library, you will know how to use them in other client libraries. You can learn about these shared features at Azure.Core . These preview libraries can be easily identified by their folder, package, and namespaces names starting with 'Azure', e.g. Azure.Storage.Blobs. The libraries released in the July 2019 preview: Azure.ApplicationModel.Configuration Azure.Messaging.EventHubs Azure.Identity.KeyVault.Keys Azure.Identity.KeyVault.Secrets Azure.Storage.Blobs Azure.Storage.Files Azure.Storage.Queues NOTE: If you need to ensure your code is ready for production, use one of the stable libraries. Client: Stable Last stable versions of packages that are production-ready. These libraries provide similar functionalities to the preview packages, as they allow you to use and consume existing resources and interact with them, for example: upload a storage blob. Stable library directories typically contain 'Microsoft.Azure' in their names, e.g. 'Microsoft.Azure.KeyVault'. Management Libraries which enable you to provision specific server resources. They are directly mirroring Azure service's REST endpoints. Management library directories typically contain the word 'Management' in their names, e.g. 'Microsoft.Azure.Management.Storage'. Need help? For reference documentation visit the Azure SDK for .NET API Reference . For tutorials, samples, quick starts, and other documentation, go to Azure for .NET Developers . File an issue via Github Issues . Check previous questions or ask new ones on StackOverflow using azure-net-sdk tag. Contributing For details on contributing to this repository, see the contributing guide . Component Build Status Client Libraries Management Libraries"
  },
  "articles/packages.html": {
    "href": "articles/packages.html",
    "title": "Package Index - azure-sdk-for-net | Azure SDK for Net",
    "keywords": "Package Index - azure-sdk-for-net Package Id Readme Changelog Published Url Azure.ApplicationModel.Configuration Readme N/A Nuget Azure.ApplicationModel.Configuration.Performance Readme N/A N/A Azure.Core Readme N/A Nuget Azure.Core.Extensions N/A N/A Nuget Azure.Identity Readme N/A Nuget Azure.Messaging.EventHubs Readme N/A Nuget Azure.Messaging.EventHubs.TrackOne Readme N/A N/A Azure.Security.KeyVault.Secrets N/A N/A Nuget Azure.Security.Keyvault.Keys N/A N/A Nuget Azure.Storage.Blobs Readme N/A Nuget Azure.Storage.Common Readme N/A Nuget Azure.Storage.Files Readme N/A Nuget Azure.Storage.Queues Readme N/A Nuget ClientRuntime.Test.Common N/A N/A N/A CodeGenerationLibrary Readme Changelog N/A Management.EventHub N/A N/A N/A Management.HDInsight N/A N/A N/A Management.HybridData N/A N/A N/A Management.ManagementGroups N/A N/A N/A Management.ServiceBus N/A N/A N/A Microsoft.Azure.ApplicationInsights.Query N/A N/A Nuget Microsoft.Azure.Batch Readme Changelog Nuget Microsoft.Azure.Batch.Common Readme Changelog N/A Microsoft.Azure.Batch.FileConventions Readme N/A N/A Microsoft.Azure.Batch.FileStaging N/A N/A Nuget Microsoft.Azure.Batch.IntegrationTestCommon Readme Changelog N/A Microsoft.Azure.CognitiveServices.AnomalyDetector N/A N/A Nuget Microsoft.Azure.CognitiveServices.FormRecognizer N/A N/A Nuget Microsoft.Azure.CognitiveServices.Knowledge.QnAMaker N/A N/A Nuget Microsoft.Azure.CognitiveServices.Language.LUIS.Authoring N/A N/A Nuget Microsoft.Azure.CognitiveServices.Language.LUIS.Runtime N/A N/A Nuget Microsoft.Azure.CognitiveServices.Language.SpellCheck N/A N/A Nuget Microsoft.Azure.CognitiveServices.Language.TextAnalytics Readme N/A Nuget Microsoft.Azure.CognitiveServices.Personalizer Readme N/A Nuget Microsoft.Azure.CognitiveServices.Search.BingAutoSuggest N/A N/A N/A Microsoft.Azure.CognitiveServices.Search.BingCustomImageSearch N/A N/A N/A Microsoft.Azure.CognitiveServices.Search.BingCustomSearch N/A N/A N/A Microsoft.Azure.CognitiveServices.Search.BingEntitySearch N/A N/A N/A Microsoft.Azure.CognitiveServices.Search.BingImageSearch N/A N/A N/A Microsoft.Azure.CognitiveServices.Search.BingLocalSearch N/A N/A N/A Microsoft.Azure.CognitiveServices.Search.BingNewsSearch N/A N/A N/A Microsoft.Azure.CognitiveServices.Search.BingVideoSearch N/A N/A N/A Microsoft.Azure.CognitiveServices.Search.BingVisualSearch N/A N/A N/A Microsoft.Azure.CognitiveServices.Search.BingWebSearch N/A N/A N/A Microsoft.Azure.CognitiveServices.Vision.ComputerVision N/A N/A Nuget Microsoft.Azure.CognitiveServices.Vision.ContentModerator N/A N/A N/A Microsoft.Azure.CognitiveServices.Vision.CustomVision.Prediction N/A N/A Nuget Microsoft.Azure.CognitiveServices.Vision.CustomVision.Training N/A N/A Nuget Microsoft.Azure.CognitiveServices.Vision.Face N/A N/A Nuget Microsoft.Azure.CognitiveServices.Vision.FormRecognizer N/A N/A N/A Microsoft.Azure.ContainerRegistry N/A N/A Nuget Microsoft.Azure.EventGrid N/A N/A Nuget Microsoft.Azure.EventHubs Readme N/A Nuget Microsoft.Azure.EventHubs.Processor N/A N/A Nuget Microsoft.Azure.EventHubs.ServiceFabricProcessor N/A N/A Nuget Microsoft.Azure.Graph.RBAC N/A N/A Nuget Microsoft.Azure.HDInsight.Job N/A N/A N/A Microsoft.Azure.Insights N/A N/A Nuget Microsoft.Azure.KeyVault Readme N/A Nuget Microsoft.Azure.KeyVault.Core N/A N/A Nuget Microsoft.Azure.KeyVault.Cryptography N/A N/A Nuget Microsoft.Azure.KeyVault.Extensions N/A N/A Nuget Microsoft.Azure.KeyVault.TestFramework Readme N/A Nuget Microsoft.Azure.KeyVault.WebKey N/A N/A Nuget Microsoft.Azure.Management.Advisor N/A N/A Nuget Microsoft.Azure.Management.Analysis N/A N/A Nuget Microsoft.Azure.Management.ApiManagement N/A Changelog Nuget Microsoft.Azure.Management.ApplicationInsights N/A N/A Nuget Microsoft.Azure.Management.Authorization N/A N/A Nuget Microsoft.Azure.Management.Automation N/A N/A Nuget Microsoft.Azure.Management.Batch N/A Changelog Nuget Microsoft.Azure.Management.BatchAI N/A N/A Nuget Microsoft.Azure.Management.Billing N/A N/A Nuget Microsoft.Azure.Management.Blueprint N/A N/A Nuget Microsoft.Azure.Management.BotService N/A N/A Nuget Microsoft.Azure.Management.Cdn N/A N/A Nuget Microsoft.Azure.Management.CognitiveServices N/A N/A Nuget Microsoft.Azure.Management.Compute N/A N/A Nuget Microsoft.Azure.Management.Consumption N/A N/A Nuget Microsoft.Azure.Management.ContainerInstance N/A N/A Nuget Microsoft.Azure.Management.ContainerRegistry N/A N/A Nuget Microsoft.Azure.Management.ContainerService N/A N/A N/A Microsoft.Azure.Management.CostManagement N/A N/A N/A Microsoft.Azure.Management.CustomProviders N/A N/A N/A Microsoft.Azure.Management.CustomerInsights N/A N/A Nuget Microsoft.Azure.Management.DataBox N/A N/A Nuget Microsoft.Azure.Management.DataBoxEdge N/A N/A N/A Microsoft.Azure.Management.DataFactory N/A Changelog Nuget Microsoft.Azure.Management.DataLake.Analytics N/A Changelog Nuget Microsoft.Azure.Management.DataLake.Store N/A Changelog Nuget Microsoft.Azure.Management.DataMigration Readme N/A Nuget Microsoft.Azure.Management.DeploymentManager N/A N/A Nuget Microsoft.Azure.Management.DevSpaces N/A N/A Nuget Microsoft.Azure.Management.DevTestLabs N/A N/A Nuget Microsoft.Azure.Management.DeviceProvisioningServices N/A N/A Nuget Microsoft.Azure.Management.Dns N/A N/A Nuget Microsoft.Azure.Management.EdgeGateway N/A N/A Nuget Microsoft.Azure.Management.EventGrid N/A N/A Nuget Microsoft.Azure.Management.FrontDoor N/A N/A Nuget Microsoft.Azure.Management.GuestConfiguration N/A Changelog Nuget Microsoft.Azure.Management.IotCentral N/A N/A Nuget Microsoft.Azure.Management.IotHub N/A N/A Nuget Microsoft.Azure.Management.KeyVault N/A N/A Nuget Microsoft.Azure.Management.Kusto N/A N/A Nuget Microsoft.Azure.Management.LabServices N/A N/A Nuget Microsoft.Azure.Management.LocationBasedServices N/A N/A Nuget Microsoft.Azure.Management.Logic N/A N/A Nuget Microsoft.Azure.Management.MachineLearning N/A N/A Nuget Microsoft.Azure.Management.MachineLearningCompute N/A N/A Nuget Microsoft.Azure.Management.ManagedServiceIdentity N/A N/A Nuget Microsoft.Azure.Management.ManagedServices N/A N/A Nuget Microsoft.Azure.Management.ManagementPartner N/A N/A Nuget Microsoft.Azure.Management.Maps N/A N/A Nuget Microsoft.Azure.Management.MarketplaceOrdering N/A N/A Nuget Microsoft.Azure.Management.Media N/A N/A Nuget Microsoft.Azure.Management.MixedReality N/A N/A Nuget Microsoft.Azure.Management.Monitor N/A Changelog Nuget Microsoft.Azure.Management.NetApp N/A N/A Nuget Microsoft.Azure.Management.Network N/A N/A Nuget Microsoft.Azure.Management.NotificationHubs N/A N/A Nuget Microsoft.Azure.Management.OperationalInsights N/A N/A Nuget Microsoft.Azure.Management.Peering N/A N/A Nuget Microsoft.Azure.Management.PolicyInsights N/A N/A Nuget Microsoft.Azure.Management.PostgreSQL Readme N/A Nuget Microsoft.Azure.Management.PowerBIDedicated N/A N/A Nuget Microsoft.Azure.Management.PowerBIEmbedded N/A N/A Nuget Microsoft.Azure.Management.PrivateDns N/A N/A Nuget Microsoft.Azure.Management.RecoveryServices N/A N/A Nuget Microsoft.Azure.Management.RecoveryServices.Backup N/A N/A Nuget Microsoft.Azure.Management.RecoveryServices.SiteRecovery N/A N/A Nuget Microsoft.Azure.Management.Redis N/A N/A Nuget Microsoft.Azure.Management.Relay N/A N/A Nuget Microsoft.Azure.Management.Reservations N/A Changelog Nuget Microsoft.Azure.Management.ResourceGraph N/A N/A Nuget Microsoft.Azure.Management.ResourceManager N/A N/A Nuget Microsoft.Azure.Management.Scheduler N/A N/A Nuget Microsoft.Azure.Management.Search N/A N/A Nuget Microsoft.Azure.Management.SecurityCenter N/A N/A Nuget Microsoft.Azure.Management.ServerManagement N/A N/A Nuget Microsoft.Azure.Management.ServiceFabric N/A N/A Nuget Microsoft.Azure.Management.SignalR N/A N/A Nuget Microsoft.Azure.Management.Sql N/A N/A Nuget Microsoft.Azure.Management.StorSimple1200Series N/A N/A N/A Microsoft.Azure.Management.StorSimple8000Series N/A N/A Nuget Microsoft.Azure.Management.Storage N/A Changelog Nuget Microsoft.Azure.Management.StorageSync N/A Changelog Nuget Microsoft.Azure.Management.StreamAnalytics N/A N/A Nuget Microsoft.Azure.Management.Subscription N/A N/A Nuget Microsoft.Azure.Management.TrafficManager N/A N/A Nuget Microsoft.Azure.Management.Websites N/A N/A Nuget Microsoft.Azure.OperationalInsights N/A N/A Nuget Microsoft.Azure.Search N/A N/A Nuget Microsoft.Azure.Search.Common N/A N/A Nuget Microsoft.Azure.Search.Data N/A N/A Nuget Microsoft.Azure.Search.Service N/A N/A Nuget Microsoft.Azure.ServiceBus Readme N/A Nuget Microsoft.Azure.ServiceBus.Performance Readme N/A N/A Microsoft.Azure.Services.AppAuthentication Readme N/A Nuget Microsoft.Azure.Test.HttpRecorder N/A N/A Nuget Microsoft.AzureStack.Management.AzureBridge.Admin N/A N/A Nuget Microsoft.AzureStack.Management.Backup.Admin N/A N/A Nuget Microsoft.AzureStack.Management.Commerce.Admin N/A N/A Nuget Microsoft.AzureStack.Management.Compute.Admin N/A N/A Nuget Microsoft.AzureStack.Management.Fabric.Admin N/A N/A Nuget Microsoft.AzureStack.Management.Gallery.Admin N/A N/A Nuget Microsoft.AzureStack.Management.InfrastructureInsights.Admin N/A N/A Nuget Microsoft.AzureStack.Management.KeyVault.Admin N/A N/A Nuget Microsoft.AzureStack.Management.Network.Admin N/A N/A Nuget Microsoft.AzureStack.Management.Storage.Admin N/A N/A Nuget Microsoft.AzureStack.Management.Subscription N/A N/A Nuget Microsoft.AzureStack.Management.Subscriptions.Admin N/A N/A Nuget Microsoft.AzureStack.Management.Update.Admin N/A N/A Nuget Microsoft.Rest.ClientRuntime N/A N/A Nuget Microsoft.Rest.ClientRuntime.Azure N/A N/A Nuget Microsoft.Rest.ClientRuntime.Azure.Authentication N/A N/A Nuget Microsoft.Rest.ClientRuntime.Azure.TestFramework N/A N/A Nuget Microsoft.Rest.ClientRuntime.Etw Readme N/A Nuget Microsoft.Rest.ClientRuntime.Log4Net Readme N/A Nuget"
  },
  "articles/intro.html": {
    "href": "articles/intro.html",
    "title": "Add your introductions here! | Azure SDK for Net",
    "keywords": "Add your introductions here!"
  },
  "articles/CONTRIBUTING.html": {
    "href": "articles/CONTRIBUTING.html",
    "title": "Contributing | Azure SDK for Net",
    "keywords": "Contributing Component Build Status Management Libraries Client Libraries Prerequisites: Install VS 2019 (Professional or higher) and make sure you have the latest updates ( https://www.visualstudio.com/ ). Client Libraries are sdks used to interact with azure resources at application run time while Management Libraries are those used to manage (create/modify/delete) Azure resources. Management Libraries TO BUILD: Open any solution, eg \"SDKs\\Compute\\Microsoft.Azure.Management.Compute.sln\" Build solution from Visual Studio Single Service from Command Line Open VS 2019 command Prompt From the root directory Invoke msbuild eng\\mgmt.proj /p:scope=Compute Build without any scope will build all management SDK's. Create single nuget package In order to build one package and run it's test msbuild eng\\mgmt.proj /t:CreateNugetPackage /p:scope=Compute Nuget package will be created in root directory under \\artifacts\\packages\\Debug (default configuration is Debug) TO TEST: Using Visual Studio: Build project in Visual Studio. Test Explorer window will get populated with tests. Select test and Run or Debug Using the command line: Run e.g. msbuild eng\\mgmt.proj /t:\"Runtests\" /p:Scope=Compute In the above example RunTests will build and run tests for Compute only or you can use command line CLI dotnet test Compute\\Microsoft.Azure.Management.Compute\\tests\\Microsoft.Azure.Management.Tests.csproj Non-Windows command line build Now you can use the same command on non-windows as above for e.g. on Ubuntu you can do something like below: dotnet msbuild eng\\mgmt.proj /t:Build /p:scope=Compute dotnet msbuild eng\\mgmt.proj /t:RunTests /p:scope=Compute dotnet msbuild eng\\mgmt.proj /t:CreateNugetPackage /p:scope=Compute dotnet msbuild build.proj /t:Util /p:UtilityName=InstallPsModules Update build tools Build tools are now downloaded as part of a nuget package under root\\restoredPackages\\microsoft.internal.netsdkbuild.mgmt.tools If for any reason there is an update to the build tools, you will then need to first delete directory root\\restoredPackages\\microsoft.internal.netsdkbuild.mgmt.tools and re-execute your build command. This will simply get the latest version of build tools. Client Libraries TO BUILD: Single Service from Command Line Open VS 2019 Command Prompt Navigate to service directory e.g. \"sdk\\eventhub\" Invoke dotnet build or Build the service.proj in the repo root, passing the directory name of the specific service as a property. e.g. dotnet build eng\\service.proj /p:ServiceDirectory=eventhub Single Service from Visual Studio Open any data-plane solution e.g. \"sdk\\eventhub\\Microsoft.Azure.EventHubs.sln\" Build solution from Visual Studio All Client Services from Command Line Open VS 2019 Command Prompt Navigate to repository root directory Invoke dotnet build eng\\service.proj TO TEST: Single Service from Command Line Open VS 2019 Command Prompt Navigate to service directory e.g. \"sdk\\eventhub\" Invoke dotnet test --filter TestCategory!=Live (Skips live tests) or run test against service.proj in the repo root, passing the directory name of the specific service as a property. e.g. dotnet test eng\\service.proj /p:ServiceDirectory=eventhub --filter TestCategory!=Live Single Service from Visual Studio Build. Test Explorer window will get populated with tests. Select test and Run or Debug All Client Services from Command Line Open VS 2019 Command Propmpt Navigate to repository root directory Invoke dotnet test eng\\service.proj --filter TestCategory!=Live On-boarding New Libraries Project Structure In sdk\\< Service Name > , you will find projects for services that have already been implemented Client library projects needs to use the $(RequiredTargetFrameworks) (defined in eng/Directory.Build.Data.props) property in its TargetFramework while management library projects should use $(SdkTargetFx) (defined in AzSdk.reference.props) Projects of related packages are grouped together in a folder following the structure specified in Repo Structure Client library packages are in a folder name like Microsoft.Azure.< ServiceName > Management library packages are in a folder named like Microsoft.Azure.Management.< Resource Provider Name > Each shipping package contains a project for their generated and /or Customization code The folder 'Generated' contains the generated code The folder 'Customizations' contains additions to the generated code - this can include additions to the generated partial classes, or additional classes that augment the SDK or call the generated code The file generate.cmd , used to generate library code for the given package, can also be found in this project Standard Process Create fork of Azure REST API Specs Create fork of Azure SDK for .NET Create your Swagger specification for your HTTP API. For more information see Introduction to Swagger - The World's Most Popular Framework for APIs Install the latest version of AutoRest and use it to generate your C# client. For more info on getting started with AutoRest, see the AutoRest repository Create a branch in your fork of Azure SDK for .NET and add your newly generated code to your project. If you don't have a project in the SDK yet, look at some of the existing projects and build one like the others. MANDATORY : Add or update tests for the newly generated code. Once added to the Azure SDK for .NET, build your local package using client or management library instructions shown in the above sections. A Pull request of your Azure SDK for .NET changes against master branch of the Azure SDK for .NET The pull requests will be reviewed and merged by the Azure SDK team New Resource Provider If you have never created an SDK for your service before, you will need the following things to get your SDK in the repo Follow the standard process described above. Project names helps in using basic heuristics in finding projects as well it's associated test projects during CI process. Create a new directory using the name of your service as specified in azure-rest-api-specs/specification Repo Follow the the directory structure below sdk\\<service name>\\<package name>\\README.md sdk\\<service name>\\<package name>\\*src* sdk\\<service name>\\<package name>\\*tests* sdk\\<service name>\\<package name>\\*samples* e.g. sdk\\eventgrid\\Microsoft.Azure.EventGrid\\src\\Microsoft.Azure.EventGrid.csproj sdk\\eventgrid\\Microsoft.Azure.EventGrid\\tests\\Microsoft.Azure.EventGrid.Tests.csproj sdk\\eventgrid\\Microsoft.Azure.Management.EventGrid\\src\\Microsoft.Azure.Management.EventGrid.csproj sdk\\eventgrid\\Microsoft.Azure.Management.EventGrid\\tests\\Microsoft.Azure.Management.EventGrid.Tests.csproj *Ensure that your service name is the same as it is specified in the azure-rest-api-specs/specification Repo, that your csproj files starts with Microsoft.Azure* , that test files end with .Tests and that management plane project files contain .Management. Copy .csproj from any other .csproj and update the following information in the new .csproj Project Properties AssemblyTitle Description VersionPrefix PackageTags PackageReleaseNotes PackageReleaseNotes are important because this information is displayed on www.nuget.org when your nuget package is published Copy existing generate.ps1 file from another service and update the ResourceProvider name that is applicable to your SDK. Resource provider refers to the relative path of your REST spec directory in Azure-Rest-Api-Specs repository During SDK generation, this path helps to locate the REST API spec from the https://github.com/Azure/azure-rest-api-specs Code Review Process Before a pull request will be considered by the Azure SDK team, the following requirements must be met: Prior to issuing the pull request: All code must have completed any necessary legal signoff for being publicly viewable (Patent review, JSR review, etc.) The changes cannot break any existing functional/unit tests that are part of the central repository. This includes all tests, even those not associated with the given feature area. Code submitted must have basic unit test coverage, and have all the unit tests pass. Testing is the full responsibility of the service team Functional tests are encouraged, and provide teams with a way to mitigate regressions caused by other code contributions. Code should be commented. Code should be fully code reviewed. Code should be able to merge without any conflicts into the dev branch being targeted. Code should pass all relevant static checks and coding guidelines set forth by the specific repository. All build warnings and code analysis warnings should be fixed prior to submission. As part of the pull request (aka, in the text box on GitHub as part of submitting the pull request): Proof of completion of the code review and test passes requirements above. Identity of QA responsible for feature testing (can be conducted post-merging of the pull request). Short description of the payload of pull request. After the pull request is submitted: Our SLA is 48 hours. When your PR is submitted someone on our team will be auto assigned the PR for review. No need to email us MS internal folks, please reach out to us via our Teams channel or Send an email to the Azure Developer Platform team adpteam@microsoft.com alias. Include all interested parties from your team as well. In the message, make sure to acknowledge that the legal signoff process is complete. Once all of the above steps are met, the following process will be followed: A member of the Azure SDK team will review the pull request on GitHub. If the pull request meets the repository's requirements, the individual will approve the pull request, merging the code into the dev branch of the source repository. The owner will then respond to the email sent as part of the pull request, informing the group of the completion of the request. If the request does not meet any of the requirements, the pull request will not be merged, and the necessary fixes for acceptance will be communicated back to the partner team. Client Library Tested OSs and .NET Versions Linux (Ubuntu 16.04) MacOS 10.13 Windows Server 2016 .NET Core 2.1 x x x Issues with Generated Code Much of the management plane SDK code is generated from metadata specs about the REST APIs. Do not submit PRs that modify generated code. Instead, File an issue describing the problem, Refer to the the AutoRest project to view and modify the generator, or Add additional methods, properties, and overloads to the SDK by adding classes in the 'Customizations' folder of a project"
  },
  "index.html": {
    "href": "index.html",
    "title": "This is the HOMEPAGE. | Azure SDK for Net",
    "keywords": "This is the HOMEPAGE . Refer to Markdown for how to write markdown files. Quick Start Notes: Add images to the images folder if the file is referencing an image."
  },
  "articles/sdk/Storage/Azure.Storage.Files/swagger/readme.html": {
    "href": "articles/sdk/Storage/Azure.Storage.Files/swagger/readme.html",
    "title": "File Storage | Azure SDK for Net",
    "keywords": "File Storage see https://aka.ms/autorest Configuration # Prevent swagger validation because it complains about vendor extensions # instead of ignoring them per the spec pipeline: swagger-document/individual/schema-validator: scope: unused # Generate file storage input-file: ./file.json output-folder: ../src/Generated clear-output-folder: false # Use the Azure C# Track 2 generator # use: C:\\src\\Storage\\Swagger\\Generator # We can't use relative paths here, so use a relative path in generate.ps1 azure-track2-csharp: true"
  },
  "articles/sdk/Storage/Azure.Storage.Files/README.html": {
    "href": "articles/sdk/Storage/Azure.Storage.Files/README.html",
    "title": "Azure Storage Files client library for .NET | Azure SDK for Net",
    "keywords": "Azure Storage Files client library for .NET Server Version: 2018-11-09 Azure Files offers fully managed file shares in the cloud that are accessible via the industry standard Server Message Block (SMB) protocol. Azure file shares can be mounted concurrently by cloud or on-premises deployments of Windows, Linux, and macOS. Additionally, Azure file shares can be cached on Windows Servers with Azure File Sync for fast access near where the data is being used. Source code | Package (NuGet) | API reference documentation | REST API documentation | Product documentation Getting started Install the package Install the Azure Storage Files client library for .NET with NuGet : dotnet add package Azure.Storage.Files --version 12.0.0-preview.1 Prerequisites You need an Azure subscription and a Storage Account to use this package. To create a new Storage Account, you can use the Azure Portal , Azure PowerShell , or the Azure CLI . Here's an example using the Azure CLI: az storage account create --name MyStorageAccount --resource-group MyResourceGroup --location westus --sku Standard_LRS Key concepts Azure file shares can be used to: Completely replace or supplement traditional on-premises file servers or NAS devices. \"Lift and shift\" applications to the cloud that expect a file share to store file application or user data. Simplify new cloud development projects with shared application settings, diagnostic shares, and Dev/Test/Debug tool file shares. Examples Create a share and upload a file using Azure.Storage; using Azure.Storage.Files; using Azure.Storage.Files.Models; // Get a connection string to our Azure Storage account. You can // obtain your connection string from the Azure Portal (click // Access Keys under Settings in the Portal Storage account blade) // or using the Azure CLI with: // // az storage account show-connection-string --name <account_name> --resource-group <resource_group> // // And you can provide the connection string to your application // using an environment variable. string connectionString = \"<connection_string>\"; // Get a reference to a share named \"sample-share\" and then create it ShareClient share = new ShareClient(connectionString, \"sample-share\"); share.Create(); // Get a reference to a directory named \"sample-dir\" and then create it DirectoryClient directory = share.GetDirectoryClient(\"sample-dir\"); directory.Create(); // Get a reference to a file named \"sample-file\" in directory \"sample-dir\" FileClient file = directory.GetFileClient(\"sample-file\"); // Upload the file using (FileStream stream = File.OpenRead(\"local-file.txt\")) { file.Create(stream.Length); file.UploadRange( FileRangeWriteType.Update, new HttpRange(0, stream.Length), stream); } Download a file // Get a connection string to our Azure Storage account. string connectionString = \"<connection_string>\"; // Get a reference to a share named \"sample-share\" ShareClient share = new ShareClient(connectionString, \"sample-share\"); // Get a reference to a directory named \"sample-dir\" DirectoryClient directory = share.GetDirectoryClient(\"sample-dir\"); // Get a reference to a file named \"sample-file\" in directory \"sample-dir\" FileClient file = directory.GetFileClient(\"sample-file\"); // Download the file StorageFileDownloadInfo download = file.Download(); using (FileStream stream = File.OpenWrite(\"downloaded-file.txt\")) { download.Content.CopyTo(stream); } Traverse a share // Get a connection string to our Azure Storage account. string connectionString = \"<connection_string>\"; // Get a reference to a share named \"sample-share\" ShareClient share = new ShareClient(connectionString, \"sample-share\"); // Track the remaining directories to walk, starting from the root Queue<DirectoryClient> remaining = new Queue<DirectoryClient>(); remaining.Enqueue(share.GetRootDirectoryClient()); while (remaining.Count > 0) { // Get all of the next directory's files and subdirectories DirectoryClient dir = remaining.Dequeue(); foreach (StorageFileItem item in dir.GetFilesAndDirectories()) { Console.WriteLine(item.Name); // Keep walking down directories if (item.IsDirectory) { remaining.Enqueue(dir.GetSubdirectoryClient(item.Name)); } } } Async APIs We fully support both synchronous and asynchronous APIs. string connectionString = \"<connection_string>\"; ShareClient share = new ShareClient(connectionString, \"sample-share\"); DirectoryClient directory = share.GetDirectoryClient(\"sample-dir\"); FileClient file = directory.GetFileClient(\"sample-file\"); // Download the file StorageFileDownloadInfo download = await file.DownloadAsync(); using (FileStream stream = File.OpenWrite(\"downloaded-file.txt\")) { await download.Content.CopyToAsync(stream); } Troubleshooting All Azure Storage File service operations will throw a StorageRequestFailedException on failure with helpful ErrorCode s . Many of these errors are recoverable. // Get a connection string to our Azure Storage account string connectionString = \"<connection_string>\"; // Try to create a share named \"sample-share\" and avoid any potential race // conditions that might arise by checking if the share exists before creating ShareClient share = new ShareClient(connectionString, \"sample-share\"); try { share.Create(); } catch (StorageRequestFailedException ex) when (ex.ErrorCode == FileErrorCode.ShareAlreadyExists) { // Ignore any errors if the share already exists } Next steps Get started with our File samples : Hello World : Upload files, download files, and traverse shares (or asynchronously ) Auth : Authenticate with connection strings, shared keys, and shared access signatures. Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit cla.microsoft.com . This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. <!-- LINKS -->"
  },
  "articles/sdk/Storage/Azure.Storage.Common/swagger/Generator/readme.html": {
    "href": "articles/sdk/Storage/Azure.Storage.Common/swagger/Generator/readme.html",
    "title": "azure-track2-csharp | Azure SDK for Net",
    "keywords": "azure-track2-csharp An early code generator for Track 2 C# client libraries on top of Azure.Core. Autorest plugin configuration The AutoRest example at https://github.com/Azure/autorest-extension-helloworld walks through the following section and the docs at http://azure.github.io/autorest/user/literate-file-formats/configuration.html and https://github.com/Azure/autorest/tree/garrett/docs/developer are the closest I could find to official explanations. # # Tell AutoRest about the plugin and how to invoke it # pipeline: azure-track2-csharp-generator: # Add `azure-track2-csharp: true` in config # or pass `--azure-track2-csharp` to the CLI scope: azure-track2-csharp # There's no `input:` section because we process the raw swagger # # Everything else configures AutoRest to save any files we write out # output-artifact: azure-track2-csharp-generator-code azure-track2-csharp-generator/emitter: input: azure-track2-csharp-generator scope: scope-azure-track2-csharp-generator/emitter scope-azure-track2-csharp-generator/emitter: input-artifact: azure-track2-csharp-generator-code output-uri-expr: $key output-artifact: azure-track2-csharp-generator-code"
  },
  "articles/sdk/Storage/Azure.Storage.Common/README.html": {
    "href": "articles/sdk/Storage/Azure.Storage.Common/README.html",
    "title": "Azure Storage Common client library for .NET | Azure SDK for Net",
    "keywords": "Azure Storage Common client library for .NET Server Version: 2018-11-09 Azure Storage is a Microsoft-managed service providing cloud storage that is highly available, secure, durable, scalable, and redundant. Azure Storage includes Azure Blobs (objects), Azure Data Lake Storage Gen2, Azure Files, and Azure Queues. The Azure.Storage.Common library provides infrastructure shared by the other Azure Storage client libraries. Source code | Package (NuGet) | API reference documentation | REST API documentation | Product documentation Getting started Install the package Install the Azure Storage client library for .NET you'd like to use with NuGet and the Azure.Storage.Common client library will be included: dotnet add package Azure.Storage.Blobs --version 12.0.0-preview.1 dotnet add package Azure.Storage.Queues --version 12.0.0-preview.1 dotnet add package Azure.Storage.Files --version 12.0.0-preview.1 Prerequisites You need an Azure subscription and a Storage Account to use this package. To create a new Storage Account, you can use the Azure Portal , Azure PowerShell , or the Azure CLI . Here's an example using the Azure CLI: az storage account create --name MyStorageAccount --resource-group MyResourceGroup --location westus --sku Standard_LRS Key concepts The Azure Storage Common client library contains shared infrastructure like authentication credentials and StorageRequestFailedException . Examples Please see the examples for Blobs , Queues , and Files . Troubleshooting All Azure Storage services will throw a StorageRequestFailedException with helpful ErrorCode s . Next steps Get started with our Common samples and then continue on with our Blobs , Queues , and Files samples. Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit cla.microsoft.com . This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. <!-- LINKS -->"
  },
  "articles/sdk/Storage/Azure.Storage.Blobs/swagger/readme.html": {
    "href": "articles/sdk/Storage/Azure.Storage.Blobs/swagger/readme.html",
    "title": "Blob Storage | Azure SDK for Net",
    "keywords": "Blob Storage see https://aka.ms/autorest Configuration # Prevent swagger validation because it complains about vendor extensions # instead of ignoring them per the spec pipeline: swagger-document/individual/schema-validator: scope: unused # Generate blob storage input-file: ./blob.json output-folder: ../src/Generated clear-output-folder: false # Use the Azure C# Track 2 generator # use: C:\\src\\Storage\\Swagger\\Generator # We can't use relative paths here, so use a relative path in generate.ps1 azure-track2-csharp: true"
  },
  "articles/sdk/Storage/Azure.Storage.Blobs/README.html": {
    "href": "articles/sdk/Storage/Azure.Storage.Blobs/README.html",
    "title": "Azure Storage Blobs client library for .NET | Azure SDK for Net",
    "keywords": "Azure Storage Blobs client library for .NET Server Version: 2018-11-09 Azure Blob storage is Microsoft's object storage solution for the cloud. Blob storage is optimized for storing massive amounts of unstructured data. Unstructured data is data that does not adhere to a particular data model or definition, such as text or binary data. Source code | Package (NuGet) | API reference documentation | REST API documentation | Product documentation Getting started Install the package Install the Azure Storage Blobs client library for .NET with NuGet : dotnet add package Azure.Storage.Blobs --version 12.0.0-preview.1 Prerequisites You need an Azure subscription and a Storage Account to use this package. To create a new Storage Account, you can use the Azure Portal , Azure PowerShell , or the Azure CLI . Here's an example using the Azure CLI: az storage account create --name MyStorageAccount --resource-group MyResourceGroup --location westus --sku Standard_LRS Key concepts Blob storage is designed for: Serving images or documents directly to a browser. Storing files for distributed access. Streaming video and audio. Writing to log files. Storing data for backup and restore, disaster recovery, and archiving. Storing data for analysis by an on-premises or Azure-hosted service. Examples Uploading a blob using Azure.Storage; using Azure.Storage.Blobs; using Azure.Storage.Blobs.Models; // Get a connection string to our Azure Storage account. You can // obtain your connection string from the Azure Portal (click // Access Keys under Settings in the Portal Storage account blade) // or using the Azure CLI with: // // az storage account show-connection-string --name <account_name> --resource-group <resource_group> // // And you can provide the connection string to your application // using an environment variable. string connectionString = \"<connection_string>\"; // Get a reference to a container named \"sample-container\" and then create it BlobContainerClient container = new BlobContainerClient(connectionString, \"sample-container\"); container.Create(); // Get a reference to a blob named \"sample-file\" in a container named \"sample-container\" BlobClient blob = container.GetBlobClient(\"sample-file\"); // Open a file and upload it's data using (FileStream file = File.OpenRead(\"local-file.jpg\")) { blob.Upload(file); } Downloading a blob // Get a reference to the public blob at https://aka.ms/bloburl BlobClient blob = new BlobClient(new Uri(\"https://aka.ms/bloburl\")); // Download the blob BlobDownloadInfo download = blob.Download(); using (FileStream file = File.OpenWrite(\"hello.jpg\")) { download.Content.CopyTo(file); } Enumerating blobs string connectionString = \"<connection_string>\"; // Get a reference to a container named \"sample-container\" BlobContainerClient container = new BlobContainerClient(connectionString, \"sample-container\"); // List all of its blobs foreach (BlobItem blob in container.GetBlobs()) { Console.WriteLine(blob.Name); } Async APIs We fully support both synchronous and asynchronous APIs. // Get a reference to the public blob at https://aka.ms/bloburl BlobClient blob = new BlobClient(new Uri(\"https://aka.ms/bloburl\")); // Download the blob BlobDownloadInfo download = await blob.DownloadAsync(); using (FileStream file = File.OpenWrite(\"hello.jpg\")) { await download.Content.CopyToAsync(file); } Authenticating with Azure.Identity The Azure Identity library provides easy Azure Active Directory support for authentication. using Azure.Identity; // Create a BlobServiceClient that will authenticate through Active Directory Uri accountUri = new Uri(\"https://MYSTORAGEACCOUNT.blob.core.windows.net/\"); BlobServiceClient client = new BlobServiceClient(accountUri, new DefaultAzureCredential()); Learn more about enabling Azure Active Directory for authentication with Azure Storage in our documentation and our samples . Troubleshooting All Blob service operations will throw a StorageRequestFailedException on failure with helpful ErrorCode s . Many of these errors are recoverable. string connectionString = \"<connection_string>\"; // Try to create a container named \"sample-container\" and avoid any potential race // conditions that might arise by checking if the container exists before creating BlobContainerClient container = new BlobContainerClient(connectionString, \"sample-container\"); try { container.Create(); } catch (StorageRequestFailedException ex) when (ex.ErrorCode == BlobErrorCode.ContainerAlreadyExists) { // Ignore any errors if the container already exists } Next steps Get started with our Blob samples : Hello World : Upload, download, and list blobs (or asynchronously ) Auth : Authenticate with connection strings, public access, shared keys, shared access signatures, and Azure Active Directory. Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit cla.microsoft.com . This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. <!-- LINKS -->"
  },
  "articles/sdk/Storage/README.html": {
    "href": "articles/sdk/Storage/README.html",
    "title": "Azure Storage libraries for .NET | Azure SDK for Net",
    "keywords": "Azure Storage libraries for .NET Azure Storage is a Microsoft-managed service providing cloud storage that is highly available, secure, durable, scalable, and redundant. Azure Storage includes Blobs (objects), Queues, and Files. Azure.Storage.Blobs is Microsoft's object storage solution for the cloud. Blob storage is optimized for storing massive amounts of unstructured data that does not adhere to a particular data model or definition, such as text or binary data. Azure.Storage.Queues is a service for storing large numbers of messages. A queue message can be up to 64 KB in size and a queue may contain millions of messages, up to the total capacity limit of a storage account. Azure.Storage.Files offers fully managed file shares in the cloud that are accessible via the industry standard Server Message Block (SMB) protocol. Azure file shares can be mounted concurrently by cloud or on-premises deployments of Windows, Linux, and macOS. Azure.Storage.Common provides infrastructure shared by the other Azure Storage client libraries like shared key authentication and exceptions. Microsoft.Azure.Management.Storage supports managing Azure Storage resources, including the creation of new storage accounts. Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit cla.microsoft.com . This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. <!-- LINKS -->"
  },
  "articles/sdk/ServiceBus/Microsoft.Azure.ServiceBus/README.html": {
    "href": "articles/sdk/ServiceBus/Microsoft.Azure.ServiceBus/README.html",
    "title": "Azure Service Bus client library for .NET | Azure SDK for Net",
    "keywords": "Azure Service Bus client library for .NET Azure Service Bus allows you to build applications that take advantage of asynchronous messaging patterns using a highly-reliable service to broker messages between producers and consumers. Azure Service Bus provides flexible, brokered messaging between client and server, along with structured first-in, first-out (FIFO) messaging, and publish/subscribe capabilities with complex routing. This directory contains the open source subset of the .NET SDK. For documentation of the complete Azure SDK, please see the Microsoft Azure .NET Developer Center . Use the client library for Azure Service Bus to: Transfer business data: leverage messaging for durable exchange of information, such as sales or purchase orders, journals, or inventory movements. Decouple applications: improve reliability and scalability of applications and services, relieving senders and receivers of the need to be online at the same time. Control how messages are processed: support traditional competing consumers for messages using queues or allow each consumer their own instance of a message using topics and subscriptions. Implement complex workflows: message sessions support scenarios that require message ordering or message deferral. Source code | Package (NuGet) | API reference documentation | Product documentation Getting started The complete Microsoft Azure SDK can be downloaded from the Microsoft Azure Downloads Page and ships with support for building deployment packages, integrating with tooling, rich command line tooling, and more. If you are not already familiar with Azure Service Bus, please review: What is Azure Service Bus . For the best development experience, developers should use the official Microsoft NuGet packages for libraries. NuGet packages are regularly updated with new functionality and hotfixes. Prerequisites Microsoft Azure Subscription: To call Microsoft Azure services, including Azure Service Bus, you need to first create an account . If you do not have an existing Azure account, you may sign up for a free trial or use your MSDN subscriber benefits. The Azure Service Bus client library shares the same Prerequisites as the Microsoft Azure SDK for .NET. Samples Code samples for the Azure Service Bus client library that detail how to get started and how to implement common scenarios can be found in the following locations: Azure Code Samples Azure Service Bus Sample Repository Azure Service Bus Documentation To build For information on building the Azure Service bus client library, please see Building the Microsoft Azure SDK for .NET Running tests Deploy the Azure Resource Manager template located at sdk/servicebus/Microsoft.Azure.ServiceBus/assets/azure-deploy-test-dependencies.json by clicking the following button: Running the above template will provision a standard Service Bus namespace along with the required entities to successfully run the unit tests. Add an Environment Variable named SERVICE_BUS_CONNECTION_STRING and set the value as the connection string of the newly created namespace. Please note that if you are using Visual Studio, you must restart Visual Studio in order to use new Environment Variables. Once you have completed the above, you can run dotnet test from the /sdk/servicebus/Microsoft.Azure.ServiceBus/tests directory. Development history For additional insight and context, the development, release, and issue history for the Azure Service Bus client library will continue to be available in read-only form, located in the stand-alone Azure Service Bus .NET repository . Versioning information The Azure Service Bus client library uses the semantic versioning scheme . Target frameworks For information about the target frameworks of the Azure Service Bus client library, please refer to the Target Frameworks of the Microsoft Azure SDK for .NET. Contributing This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. Additional documentation Azure Service Bus General Documentation Azure Service Bus REST API Reference Azure Service Bus SDK for .NET Documentation"
  },
  "api/index.html": {
    "href": "api/index.html",
    "title": "PLACEHOLDER | Azure SDK for Net",
    "keywords": "PLACEHOLDER TODO: Add .NET projects to the src folder and run docfx to generate REAL API Documentation !"
  },
  "articles/sdk/Storage/Microsoft.Azure.Management.Storage/changelog.html": {
    "href": "articles/sdk/Storage/Microsoft.Azure.Management.Storage/changelog.html",
    "title": "Microsoft.Azure.Management.Storage release notes | Azure SDK for Net",
    "keywords": "Microsoft.Azure.Management.Storage release notes Changes in 12.0.0 Support Create or Update Storage Account with AzureFilesIdentityBasedAuthentication.DirectoryServiceOptions as 'AADDS' or 'None'. Breaking changes Remove StorageAccount property: EnableAzureFilesAadIntegration. BlobContainers.List() return value type change from ListContainerItems to IPage . Changes in 11.0.0 Upgrade to rest api version 2019-04-01 Support Revoke UserDelegationKeys on a specified Storage account Support Enable/Disable Automatic Snapshot Policy on Blob Service Properties of a specified Storage account Support Create or Update Storage Account with Sku Standard_GZRS and Standard_RAGZRS Breaking changes Change the type of StorageAccount.Kind, StorageAccountCreateParameters.Kind, StorageAccountUpdateParameters.Kind, from enum to string. Change the type of StorageAccount.Sku.Name, StorageAccountCreateParameters.Sku.Name, StorageAccountUpdateParameters.Sku.Name, from enum to string. Changes in 10.0.0 Microsoft.Azure.Management.Storage SDK is GA Upgrade to rest api version 2018-11-01 Breaking changes Change input parameter of StorageManagementClient.ManagementPolicies.CreateOrUpdate(), the input policy change from Json to ManagementPolicySchema object Change output of StorageManagementClient.StorageAccounts.GetManagementPolicies(), the output policy change from Json to ManagementPolicySchema object Changes in 9.2.0-preview Add \"CanFailover\" to Storage Account Expend Property GeoReplicationStats Breaking changes Change StorageAccountCreateParameters.CustomDomain.UseSubDomain to StorageAccountCreateParameters.CustomDomain.UseSubDomainName Change StorageAccountUpdateParameters.CustomDomain.UseSubDomain to StorageAccountUpdateParameters.CustomDomain.UseSubDomainName Changes in 9.1.0-preview Support trigger Storage Account Failover on RA-GRS accounts, in case of availability issues. Support expand the properties of get Storage Accounts, to get Account geoReplicationStats. Changes in 9.0.0-preview Upgrade to rest api version 2018-07-01 (ManagementPolicies API still use 2018-03-01-preview) Support Create Storage Account with kind FileStorage, BlockBlobStorage and Sku Premium_ZRS Support Create or Upgrade Storage Account with Property EnableAzureFilesAadIntegration Breaking changes Rename StorageManagementClient.StorageAccounts.CreateOrUpdateManagementPolicies() to StorageManagementClient.ManagementPolicies.CreateOrUpdate() Rename StorageManagementClient.StorageAccounts.GetManagementPolicies() to StorageManagementClient.ManagementPolicies.Get() Rename StorageManagementClient.StorageAccounts.DeleteManagementPolicies() to StorageManagementClient.ManagementPolicies.Delete() StorageManagementClient.Usages.List() is removed, as api version 2018-07-01 not support get global storage resource usage, and only support get storage resource usage by location with StorageManagementClient.Usages.ListByLocation(). Changes in 8.1.0-preview Support HDFS feature Changes in 8.0.0-preview Support Management Policy feature Upgrade to rest api version 2018-03-01-preview Breaking changes Rename StorageManagementClient.Usage to StorageManagementClient.Usages Rename StorageManagementClient.Usage.List() to StorageManagementClient.Usages.List() Rename StorageManagementClient.Usage.ListByLocation() to StorageManagementClient.Usages.ListByLocation() Changes in 7.2.0-preview Support WORM feature Add StorageManagementClient.Usage.ListByLocation() to support get storage resource usage by location Upgrade to rest api version 2018-02-01 Changes in 7.1.0-preview Support Create or Upgrade Storage Account with kind StorageV2 Changes in 7.0.0-preview Breaking changes When updating storage virtual networks, NetworkRuleSet is used instead of NetworkAcl. Notes When updating storage virtual networks, virtualNetworkResourceId is limited to be resource ID of a subnet. Added Skus.list() operation, which could list all the available skus for the subscription."
  },
  "articles/sdk/Storage/Azure.Storage.Queues/swagger/readme.html": {
    "href": "articles/sdk/Storage/Azure.Storage.Queues/swagger/readme.html",
    "title": "Queue Storage | Azure SDK for Net",
    "keywords": "Queue Storage see https://aka.ms/autorest Configuration # Prevent swagger validation because it complains about vendor extensions # instead of ignoring them per the spec pipeline: swagger-document/individual/schema-validator: scope: unused # Generate queue storage input-file: ./queue.json output-folder: ../src/Generated clear-output-folder: false # Use the Azure C# Track 2 generator # use: C:\\src\\Storage\\Swagger\\Generator # We can't use relative paths here, so use a relative path in generate.ps1 azure-track2-csharp: true"
  },
  "articles/sdk/Storage/Azure.Storage.Queues/README.html": {
    "href": "articles/sdk/Storage/Azure.Storage.Queues/README.html",
    "title": "Azure Storage Queues client library for .NET | Azure SDK for Net",
    "keywords": "Azure Storage Queues client library for .NET Server Version: 2018-11-09 Azure Queue storage is a service for storing large numbers of messages that can be accessed from anywhere in the world via authenticated calls using HTTP or HTTPS. A single queue message can be up to 64 KB in size, and a queue can contain millions of messages, up to the total capacity limit of a storage account. Source code | Package (NuGet) | API reference documentation | REST API documentation | Product documentation Getting started Install the package Install the Azure Storage Queues client library for .NET with NuGet : dotnet add package Azure.Storage.Queues --version 12.0.0-preview.1 Prerequisites You need an Azure subscription and a Storage Account to use this package. To create a new Storage Account, you can use the Azure Portal , Azure PowerShell , or the Azure CLI . Here's an example using the Azure CLI: az storage account create --name MyStorageAccount --resource-group MyResourceGroup --location westus --sku Standard_LRS Key concepts Common uses of Queue storage include: Creating a backlog of work to process asynchronously Passing messages between different parts of a distributed application Examples Enqueue messages using Azure.Storage; using Azure.Storage.Queues; using Azure.Storage.Queues.Models; // Get a connection string to our Azure Storage account. You can // obtain your connection string from the Azure Portal (click // Access Keys under Settings in the Portal Storage account blade) // or using the Azure CLI with: // // az storage account show-connection-string --name <account_name> --resource-group <resource_group> // // And you can provide the connection string to your application // using an environment variable. string connectionString = \"<connection_string>\"; // Get a reference to a queue named \"sample-queue\" and then create it QueueClient queue = new QueueClient(connectionString, \"sample-queue\"); queue.Create(); // Add a message to our queue queue.EnqueueMessage(\"Hello, Azure!\"); Dequeue messages // Get a connection string to our Azure Storage account. string connectionString = \"<connection_string>\"; // Get a reference to a queue named \"sample-queue\" and then create it QueueClient queue = new QueueClient(connectionString, \"sample-queue\"); queue.Create(); // Add several messages to the queue queue.EnqueueMessage(\"first\"); queue.EnqueueMessage(\"second\"); queue.EnqueueMessage(\"third\"); // Get the next 10 messages from the queue foreach (DequeuedMessage message in queue.DequeueMessages(maxMessages: 10).Value) { // \"Process\" the message Console.WriteLine(message.MessageText) // Let the service know we finished with the message and // it can be safely deleted. queue.DeleteMessage(message.MessageId, message.PopReceipt); } Async APIs We fully support both synchronous and asynchronous APIs. // Get a connection string to our Azure Storage account. string connectionString = \"<connection_string>\"; // Get a reference to a queue named \"sample-queue\" and then create it QueueClient queue = new QueueClient(connectionString, \"sample-queue\"); await queue.CreateAsync(); // Add a message to our queue await queue.EnqueueMessageAsync(\"Hello, Azure!\"); Authenticating with Azure.Identity The Azure Identity library provides easy Azure Active Directory support for authentication. using Azure.Identity; // Create a QueueClient that will authenticate through Active Directory Uri accountUri = new Uri(\"https://MYSTORAGEACCOUNT.blob.core.windows.net/\"); QueueClient queue = new QueueClient(accountUri, new DefaultAzureCredential()); Learn more about enabling Azure Active Directory for authentication with Azure Storage in our documentation and our samples . Troubleshooting All Azure Storage Queue service operations will throw a StorageRequestFailedException on failure with helpful ErrorCode s . Many of these errors are recoverable. // Get a connection string to our Azure Storage account string connectionString = \"<connection_string>\"; // Try to create a queue named \"sample-queue\" and avoid any potential race // conditions that might arise by checking if the queue exists before creating QueueClient queue = new QueueClient(connectionString, \"sample-queue\"); try { queue.Create(); } catch (StorageRequestFailedException ex) when (ex.ErrorCode == QueueErrorCode.QueueAlreadyExists) { // Ignore any errors if the queue already exists } Next steps Get started with our Queue samples : Hello World : Enqueue, Dequeue, Peek, and Update queue messages (or asynchronously ) Auth : Authenticate with connection strings, shared keys, shared access signatures, and Azure Active Directory. Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit cla.microsoft.com . This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. <!-- LINKS -->"
  },
  "articles/sdk/KeyVault/Microsoft.Azure.KeyVault/README.html": {
    "href": "articles/sdk/KeyVault/Microsoft.Azure.KeyVault/README.html",
    "title": "Microsoft Azure Keyvault SDK for .NET | Azure SDK for Net",
    "keywords": "Microsoft Azure Keyvault SDK for .NET The Microsoft Azure Key Vault SDK for .NET allows you to build secure Azure applications that can access secrets, keys, and certificates that a encrypted at rest with hardware security modules. This directory contains the open source subset of the .NET SDK. For documentation of the complete Azure SDK, please see the Microsoft Azure .NET Developer Center . Features Secrets Create, Read, Update, Delete, and Recover Secrets Backup and Restore Secrets Keys Create, Read, Update, Delete, and Recover Keys Import, Backup and Restore Keys Encrypt, Decrypt, Wrap, Unwrap, Sign and Verify cryptographic Key operations Certificates Create, Read, Update, Delete, and Recover Certificates Create, Read, Update, and Delete certificate renewal properties Create, Read, Update, and Delete certificate issuers Storage Accounts Add, Read, Update, and Remove Storage Accounts managed by the Key Vault Create, Read, Update, and Delete SAS definitions Getting Started The complete Microsoft Azure SDK can be downloaded from the Microsoft Azure Downloads Page and ships with support for building deployment packages, integrating with tooling, rich command line tooling, and more. Please review Get started with Azure Key Vault if you are not familiar with Azure Key Vault. For the best development experience, developers should use the official Microsoft NuGet packages for libraries. NuGet packages are regularly updated with new functionality and hotfixes. Requirements Microsoft Azure Subscription: To call Microsoft Azure services, you need to first create an account . Sign up for a free trial or use your MSDN subscriber benefits. Hosting: To host your .NET code in Microsoft Azure, you additionally need to download the full Microsoft Azure SDK for .NET - which includes packaging, emulation, and deployment tools, or use Microsoft Azure Web Sites to deploy ASP.NET web applications. Download Packages Microsoft.Azure.KeyVault Microsoft.Azure.KeyVault.Core Microsoft.Azure.KeyVault.WebKey Microsoft.Azure.KeyVault.Cryptography Microsoft.Azure.KeyVault.Extensions Versioning Information The Key Vault SDK uses the semantic versioning scheme. Target Frameworks For information about the target frameworks of the Key Vault SDK, please refer to the Target Frameworks of the Microsoft Azure SDK for .NET. Prerequisites The Key Vault Client Library shares the same Prerequisites as the Microsoft Azure SDK for .NET. To Build For information on building the Azure Key Vault SDK, please see Building the Microsoft Azure SDK for .NET . Running Tests Tests for the Azure Key Vault SDK are run in the same manner as the rest of the tests for the Azure SDK for .NET. For information please see how to run tests . Samples Code samples for the Azure Key Vault SDK are available on Azure Code Samples . Additional Documentation Azure Key Vault General Documentation Azure Key Vault REST API Reference Azure Key Vault SDK for .NET Documentation Contributing This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments."
  },
  "articles/sdk/KeyVault/Azure.Security.KeyVault.Secrets/Readme.html": {
    "href": "articles/sdk/KeyVault/Azure.Security.KeyVault.Secrets/Readme.html",
    "title": "Azure Key Vault Secret client library for .NET | Azure SDK for Net",
    "keywords": "Azure Key Vault Secret client library for .NET Azure Key Vault is a cloud service that provides a secure storage of secrets, such as passwords and database connection strings. Secret client library allows you to securely store and control the access to tokens, passwords, API keys, and other secrets. This library offers operations to create, retrieve, update, delete, purge, backup, restore and list the secrets and its versions. Source code | Package (NuGet) | API reference documentation | Product documentation | Samples Getting started Install the package Install the Azure Key Vault client library for .NET with NuGet : Install-Package Azure.Security.KeyVault.Secrets -IncludePrerelease Prerequisites An Azure subscription . An existing Key Vault. If you need to create a Key Vault, you can use the Azure Portal or Azure CLI . If you use the Azure CLI, replace <your-resource-group-name> and <your-key-vault-name> with your own, unique names: az keyvault create --resource-group <your-resource-group-name> --name <your-key-vault-name> Authenticate the client In order to interact with the Key Vault service, you'll need to create an instance of the SecretClient class. You would need a vault url and client secret credentials (client id, client secret, tenant id) to instantiate a client object. Client secret credential authentication is being used in this getting started section but you can find more ways to authenticate with Azure identity . Create/Get credentials Use the Azure CLI snippet below to create/get client secret credentials. Create a service principal and configure its access to Azure resources: az ad sp create-for-rbac -n <your-application-name> --skip-assignment Output: { \"appId\": \"generated-app-ID\", \"displayName\": \"dummy-app-name\", \"name\": \"http://dummy-app-name\", \"password\": \"random-password\", \"tenant\": \"tenant-ID\" } Use the returned credentials above to set AZURE_CLIENT_ID (appId), AZURE_CLIENT_SECRET (password) and AZURE_TENANT_ID (tenant) environment variables. The following example shows a way to do this in Powershell: $Env:AZURE_CLIENT_ID=\"generated-app-ID\" $Env:AZURE_CLIENT_SECRET=\"random-password\" $Env:AZURE_TENANT_ID=\"tenant-ID\" Grant the above mentioned application authorization to perform secret operations on the key vault: az keyvault set-policy --name <your-key-vault-name> --spn $AZURE_CLIENT_ID --secret-permissions backup delete get list set --secret-permissions: Accepted values: backup, delete, get, list, purge, recover, restore, set Use the above mentioned Key Vault name to retrieve details of your Vault which also contains your Key Vault URL: az keyvault show --name <your-key-vault-name> Create SecretClient Once you've populated the AZURE_CLIENT_ID , AZURE_CLIENT_SECRET and AZURE_TENANT_ID environment variables and replaced your-vault-url with the above returned URI, you can create the SecretClient : using Azure.Identity; using Azure.Security.KeyVault.Secrets; // Create a new secret client using the default credential from Azure.Identity var client = new SecretClient(vaultUri: <your-vault-url>, credential: new DefaultAzureCredential()); // Create a new secret using the secret client Secret secret = client.Set(\"secret-name\", \"secret-value\"); new DefaultAzureCredential(): Uses the environment variables previously set ( AZURE_CLIENT_ID , AZURE_CLIENT_SECRET , and AZURE_TENANT_ID ) Key concepts Secret A secret is the fundamental resource within Azure KeyVault. From a developer's perspective, Key Vault APIs accept and return secret values as strings. Secret Client: A SecretClient providing both synchronous and asynchronous operations exists in the SDK allowing for selection of a client based on an application's use case. Once you've initialized a SecretClient, you can interact with the primary resource types in Key Vault. Examples The Azure.Security.KeyVault.Secrets package supports synchronous and asynchronous APIs. The following section provides several code snippets using the above created client , covering some of the most common Azure Key Vault Secret service related tasks: Sync examples Create a Secret Retrieve a Secret Update an existing Secret Delete a Secret List Secrets Async examples Create a Secret Create a Secret Set creates a Secret to be stored in the Azure Key Vault. If a secret with the same name already exists, then a new version of the secret is created. Secret secret = client.Set(\"secret-name\", \"secret-value\"); Console.WriteLine(secret.Name); Console.WriteLine(secret.Value); Console.WriteLine(secret.Version); Console.WriteLine(secret.Enabled); Retrieve a Secret Get retrieves a secret previously stored in the Key Vault. Secret secret = client.Get(\"secret-name\"); Console.WriteLine(secret.Name); Console.WriteLine(secret.Value); Update an existing Secret Update updates a secret previously stored in the Key Vault. Secret secret = new Secret(\"secret-name\"); // Clients may specify the content type of a secret to assist in interpreting the secret data when it's retrieved secret.ContentType = \"text/plain\"; // You can specify additional application-specific metadata in the form of tags. secret.Tags[\"foo\"] = \"updated tag\"; SecretBase updatedSecret = client.Update(secret); Console.WriteLine(updatedSecret.Name); Console.WriteLine(updatedSecret.Value); Console.WriteLine(updatedSecret.Version); Console.WriteLine(updatedSecret.ContentType); Delete a Secret Delete deletes a secret previously stored in the Key Vault. When soft-delete is not enabled for the Key Vault, this operation permanently deletes the secret. DeletedSecret secret = client.Delete(\"secret-name\"); Console.WriteLine(secret.Name); Console.WriteLine(secret.Value); List secrets This example lists all the secrets in the specified Key Vault. IEnumerable<Response<SecretBase>> allSecrets = client.GetSecrets(); foreach (Secret secret in allSecrets) { Console.WriteLine(secret.Name); } Async create a secret Async APIs are identical to their synchronous counterparts. Note that all methods end with Async . This example creates a secret in the Key Vault with the specified optional arguments. Secret secret = await client.SetAsync(\"secret-name\", \"secret-value\"); Console.WriteLine(secret.Name); Console.WriteLine(secret.Value); Troubleshooting General When you interact with the Azure Key Vault Secret client library using the .NET SDK, errors returned by the service correspond to the same HTTP status codes returned for REST API requests. For example, if you try to retrieve a Secret that doesn't exist in your Key Vault, a 404 error is returned, indicating Not Found . try { Secret secret = client.Get(\"some_secret\"); } catch (RequestFailedException ex) { System.Console.WriteLine(ex.ToString()); } You will notice that additional information is logged, like the Client Request ID of the operation. Message: Azure.RequestFailedException : Service request failed. Status: 404 (Not Found) Content: {\"error\":{\"code\":\"SecretNotFound\",\"message\":\"Secret not found: some_secret\"}} Headers: Cache-Control: no-cache Pragma: no-cache Server: Microsoft-IIS/10.0 x-ms-keyvault-region: westus x-ms-request-id: 625f870e-10ea-41e5-8380-282e5cf768f2 x-ms-keyvault-service-version: 1.1.0.866 x-ms-keyvault-network-info: addr=131.107.174.199;act_addr_fam=InterNetwork; X-AspNet-Version: 4.0.30319 X-Powered-By: ASP.NET Strict-Transport-Security: max-age=31536000;includeSubDomains X-Content-Type-Options: nosniff Date: Tue, 18 Jun 2019 16:02:11 GMT Content-Length: 75 Content-Type: application/json; charset=utf-8 Expires: -1 Next steps Several Key Vault Secrets client library samples are available to you in this GitHub repository. These samples provide example code for additional scenarios commonly encountered while working with Key Vault: HelloWorld.cs and HelloWorldAsync.cs - for working with Azure Key Vault, including: Create a secret Get an existing secret Update an existing secret Delete secret BackupAndRestore.cs and BackupAndRestoreAsync.cs - Contains the code snippets working with Key Vault secrets, including: Backup and recover a secret GetSecrets.cs and GetSecretsAsync.cs - Example code for working with Key Vault secrets, including: Create secrets List all secrets in the Key Vault Update secrets in the Key Vault List versions of a specified secret Delete secrets from the Key Vault List deleted secrets in the Key Vault Additional Documentation For more extensive documentation on Azure Key Vault, see the API reference documentation . For Keys client library see Keys client library . For Certificates client library see Certificates client library . Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.microsoft.com . When you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. <!-- LINKS -->"
  },
  "articles/sdk/KeyVault/Azure.Security.KeyVault.Secrets/ChangeLog.html": {
    "href": "articles/sdk/KeyVault/Azure.Security.KeyVault.Secrets/ChangeLog.html",
    "title": "Release History | Azure SDK for Net",
    "keywords": "Release History 4.0.0-preview.1 (2019-06-28) Version 4.0.0-preview.1 is the first preview of our efforts to create a user-friendly client library for Azure Key Vault. For more information about preview releases of other Azure SDK libraries, please visit https://aka.ms/azure-sdk-preview1-net . This library is not a direct replacement for Microsoft.Azure.KeyVault . Applications using that library would require code changes to use Azure.Security.KeyVault.Secrets . This package's documentation and samples demonstrate the new API. Major changes from Microsoft.Azure.KeyVault Packages scoped by functionality Azure.Security.KeyVault.Secrets contains a client for secret operations. Azure.Security.KeyVault.Keys contains a client for key operations. Client instances are scoped to vaults (an instance interacts with one vault only). Asynchronous and synchronous APIs in the Azure.Security.KeyVault.Secrets package. Authentication using Azure.Identity credentials see this package's documentation , and the Azure Identity documentation for more information Microsoft.Azure.KeyVault features not implemented in this release: Certificate management APIs National cloud support. This release supports public global cloud vaults, e.g. https://{vault-name}.vault.azure.net"
  },
  "articles/sdk/KeyVault/Azure.Security.KeyVault.Keys/Readme.html": {
    "href": "articles/sdk/KeyVault/Azure.Security.KeyVault.Keys/Readme.html",
    "title": "Azure Key Vault Key client library for .NET | Azure SDK for Net",
    "keywords": "Azure Key Vault Key client library for .NET Azure Key Vault is a cloud service that provides secure storage of keys for encrypting your data. Multiple keys, and multiple versions of the same key, can be kept in the Key Vault. Cryptographic keys in Key Vault are represented as JSON Web Key (JWK) objects. The Azure Key Vault keys library client supports RSA keys and Elliptic Curve (EC) keys, each with corresponding support in hardware security modules (HSM). It offers operations to create, retrieve, update, delete, purge, backup, restore and list the keys and its versions. Source code | Package (NuGet) | API reference documentation | Product documentation | Samples Getting started Install the package Install the Azure Key Vault Keys client library for .NET with NuGet : Install-Package Azure.Security.KeyVault.Keys -IncludePrerelease Prerequisites An Azure subscription . An existing Key Vault. If you need to create a Key Vault, you can use the Azure Portal or Azure CLI . If you use the Azure CLI, replace <your-resource-group-name> and <your-key-vault-name> with your own, unique names: az keyvault create --resource-group <your-resource-group-name> --name <your-key-vault-name> Authenticate the client In order to interact with the Key Vault service, you'll need to create an instance of the KeyClient class. You would need a vault url and client secret credentials (client id, client secret, tenant id) to instantiate a client object. Client secret credential authentication is being used in this getting started section but you can find more ways to authenticate with Azure identity . Create/Get credentials Use the Azure CLI snippet below to create/get client secret credentials. Create a service principal and configure its access to Azure resources: az ad sp create-for-rbac -n <your-application-name> --skip-assignment Output: { \"appId\": \"generated-app-ID\", \"displayName\": \"dummy-app-name\", \"name\": \"http://dummy-app-name\", \"password\": \"random-password\", \"tenant\": \"tenant-ID\" } Use the returned credentials above to set AZURE_CLIENT_ID (appId), AZURE_CLIENT_SECRET (password) and AZURE_TENANT_ID (tenant) environment variables. The following example shows a way to do this in Powershell: $Env:AZURE_CLIENT_ID=\"generated-app-ID\" $Env:AZURE_CLIENT_SECRET=\"random-password\" $Env:AZURE_TENANT_ID=\"tenant-ID\" Grant the above mentioned application authorization to perform key operations on the key vault: az keyvault set-policy --name <your-key-vault-name> --spn $AZURE_CLIENT_ID --key-permissions backup delete get list create --key-permissions: Accepted values: backup, create, decrypt, delete, encrypt, get, import, list, purge, recover, restore, sign, unwrapKey, update, verify, wrapKey Use the above mentioned Key Vault name to retrieve details of your Vault which also contains your Key Vault URL: az keyvault show --name <your-key-vault-name> Create KeyClient Once you've populated the AZURE_CLIENT_ID , AZURE_CLIENT_SECRET and AZURE_TENANT_ID environment variables and replaced your-vault-url with the above returned URI, you can create the KeyClient : using Azure.Identity; using Azure.Security.KeyVault.Keys; // Create a new key client using the default credential from Azure.Identity var client = new KeyClient(vaultUri: <your-vault-url>, credential: new DefaultAzureCredential()); // Create a new key using the key client Key key = await Client.CreateKey(\"key-name\", KeyType.EllipticCurve); new DefaultAzureCredential(): Uses the environment variables previously set ( AZURE_CLIENT_ID , AZURE_CLIENT_SECRET , and AZURE_TENANT_ID ). Key concepts Keys Azure Key Vault supports multiple key types and algorithms, and enables the use of Hardware Security Modules (HSM) for high value keys. Key Client: A KeyClient providing both synchronous and asynchronous operations exists in the SDK allowing for selection of a client based on an application's use case. Once you've initialized a KeyClient, you can interact with the primary resource types in Key Vault. Examples The Azure.Security.KeyVault.Keys package supports synchronous and asynchronous APIs. The following section provides several code snippets using the above created client , covering some of the most common Azure Key Vault Key service related tasks: Sync examples Create a Key Retrieve a Key Update an existing Key Delete a Key List Keys Async examples Create a Key Create a Key Create a Key to be stored in the Azure Key Vault. If a key with the same name already exists, then a new version of the key is created. // Create a key. Note that you can specify the type of key // i.e. Elliptic curve, Hardware Elliptic Curve, RSA Key key = client.CreateKey(\"key-name\", KeyType.EllipticCurve); Console.WriteLine(key.Name); Console.WriteLine(key.KeyMaterial.KeyType); // Create a software RSA key var rsaCreateKey = new RsaKeyCreateOptions(\"rsa-key-name\", hsm: false); Key rsaKey = client.CreateRsaKey(rsaCreateKey); Console.WriteLine(rsaKey.Name); Console.WriteLine(rsaKey.KeyMaterial.KeyType); // Create a hardware Elliptic Curve key var echsmkey = new EcKeyCreateOptions(\"ec-key-name\", hsm: true); Key ecKey = client.CreateEcKey(echsmkey); Console.WriteLine(ecKey.Name); Console.WriteLine(ecKey.KeyMaterial.KeyType); Retrieve a Key GetKey retrieves a key previously stored in the Key Vault. Key key = client.GetKey(\"key-name\"); Console.WriteLine(key.Name); Console.WriteLine(key.KeyMaterial.KeyType); Update an existing Key UpdateKey updates a key previously stored in the Key Vault. Key key = client.CreateKey(\"key-name\", KeyType.EllipticCurve); // You can specify additional application-specific metadata in the form of tags. key.Tags[\"foo\"] = \"updated tag\"; KeyBase updatedKey = client.UpdateKey(key, key.KeyMaterial.KeyOps); Console.WriteLine(updatedKey.Name); Console.WriteLine(updatedKey.Version); Console.WriteLine(updatedKey.Updated); Delete a Key DeleteKey deletes a key previously stored in the Key Vault. When soft-delete is not enabled for the Key Vault, this operation permanently deletes the key. DeletedKey key = client.DeleteKey(\"key-name\"); Console.WriteLine(key.Name); Console.WriteLine(key.DeletedDate); List Keys This example lists all the keys in the specified Key Vault. IEnumerable<Response<KeyBase>> allKeys = client.GetKeys(); foreach (Key key in allKeys) { Console.WriteLine(key.Name); } Async create a Key Async APIs are identical to their synchronous counterparts. Note that all methods end with Async . // Create a key of any type Key key = await client.CreateKeyAsync(\"key-name\", KeyType.EllipticCurve); Console.WriteLine(key.Name); Console.WriteLine(key.KeyMaterial.KeyType); // Create a software RSA key var rsaCreateKey = new RsaKeyCreateOptions(\"rsa-key-name\", hsm: false); Key rsaKey = await client.CreateRsaKeyAsync(rsarsaCreateKeyKey); Console.WriteLine(rsaKey.Name); Console.WriteLine(rsaKey.KeyMaterial.KeyType); // Create a hardware Elliptic Curve key var echsmkey = new EcKeyCreateOptions(\"ec-key-name\", hsm: true); Key ecKey = await client.CreateEcKeyAsync(echsmkey); Console.WriteLine(ecKey.Name); Console.WriteLine(ecKey.KeyMaterial.KeyType); Troubleshooting General When you interact with the Azure Key Vault Key client library using the .NET SDK, errors returned by the service correspond to the same HTTP status codes returned for REST API requests. For example, if you try to retrieve a Key that doesn't exist in your Key Vault, a 404 error is returned, indicating Not Found . try { Key key = await Client.GetKeyAsync(\"some_key\"); } catch (RequestFailedException ex) { System.Console.WriteLine(ex.ToString()); } You will notice that additional information is logged, like the Client Request ID of the operation. Message: Azure.RequestFailedException : Service request failed. Status: 404 (Not Found) Content: {\"error\":{\"code\":\"KeyNotFound\",\"message\":\"Key not found: some_key\"}} Headers: Cache-Control: no-cache Pragma: no-cache Server: Microsoft-IIS/10.0 x-ms-keyvault-region: westus x-ms-request-id: 625f870e-10ea-41e5-8380-282e5cf768f2 x-ms-keyvault-service-version: 1.1.0.866 x-ms-keyvault-network-info: addr=131.107.174.199;act_addr_fam=InterNetwork; X-AspNet-Version: 4.0.30319 X-Powered-By: ASP.NET Strict-Transport-Security: max-age=31536000;includeSubDomains X-Content-Type-Options: nosniff Date: Tue, 18 Jun 2019 16:02:11 GMT Content-Length: 75 Content-Type: application/json; charset=utf-8 Expires: -1 Next steps Several Key Vault Keys client library samples are available to you in this GitHub repository. These samples provide example code for additional scenarios commonly encountered while working with Key Vault: HelloWorld.cs and HelloWorldAsync.cs - for working with Azure Key Vault, including: Create a key Get an existing key Update an existing key Delete a key BackupAndRestore.cs and BackupAndRestoreAsync.cs - Contains the code snippets working with Key Vault keys, including: Backup and recover a key GetKeys.cs and GetKeysAsync.cs - Example code for working with Key Vault keys, including: Create keys List all keys in the Key Vault Update keys in the Key Vault List versions of a specified key Delete keys from the Key Vault List deleted keys in the Key Vault Additional Documentation For more extensive documentation on Azure Key Vault, see the API reference documentation . For Secrets client library see Secrets client library . For Certificates client library see Certificates client library . Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.microsoft.com . When you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. <!-- LINKS -->"
  },
  "articles/sdk/KeyVault/Azure.Security.KeyVault.Keys/ChangeLog.html": {
    "href": "articles/sdk/KeyVault/Azure.Security.KeyVault.Keys/ChangeLog.html",
    "title": "Release History | Azure SDK for Net",
    "keywords": "Release History 4.0.0-preview.1 (2019-06-28) Version 4.0.0-preview.1 is the first preview of our efforts to create a user-friendly client library for Azure Key Vault. For more information about preview releases of other Azure SDK libraries, please visit https://aka.ms/azure-sdk-preview1-net . This library is not a direct replacement for Microsoft.Azure.KeyVault . Applications using that library would require code changes to use Azure.Security.KeyVault.Keys . This package's documentation and samples demonstrate the new API. Major changes from Microsoft.Azure.KeyVault Packages scoped by functionality Azure.Security.KeyVault.Keys contains a client for key operations. Azure.Security.KeyVault.Secrets contains a client for secret operations. Client instances are scoped to vaults (an instance interacts with one vault only). Asynchronous and synchronous APIs in the Azure.Security.KeyVault.Keys package. Authentication using Azure.Identity credentials see this package's documentation , and the Azure Identity documentation for more information Microsoft.Azure.KeyVault features not implemented in this release: Certificate management APIs Cryptographic operations, e.g. sign, un/wrap, verify, en- and decrypt National cloud support. This release supports public global cloud vaults, e.g. https://{vault-name}.vault.azure.net"
  },
  "articles/sdk/Identity/Azure.Identity/README.html": {
    "href": "articles/sdk/Identity/Azure.Identity/README.html",
    "title": "Azure Identity client library for .NET | Azure SDK for Net",
    "keywords": "Azure Identity client library for .NET The Azure Identity library provides Azure Active Directory token authentication support across the Azure SDK. It provides a set of TokenCredential implementations which can be used to construct Azure SDK clients which support AAD token authentication. This library is in preview and currently supports: Service principal authentication Managed identity authentication Source code | Package (nuget) | API reference documentation (Coming Soon) | Azure Active Directory documentation Getting started Install the package Install the Azure Identity client library for .NET with NuGet : Install-Package Azure.Identity -IncludePrerelease Prerequisites An Azure subscription . An existing Azure Active Directory service principal. If you need to create a service principal, you can use the Azure Portal or Azure CLI . Creating a Service Principal with the Azure CLI Use the Azure CLI snippet below to create/get client secret credentials. Create a service principal and configure its access to Azure resources: az ad sp create-for-rbac -n <your-application-name> --skip-assignment Output: { \"appId\": \"generated-app-ID\", \"displayName\": \"dummy-app-name\", \"name\": \"http://dummy-app-name\", \"password\": \"random-password\", \"tenant\": \"tenant-ID\" } Use the returned credentials above to set AZURE_CLIENT_ID (appId), AZURE_CLIENT_SECRET (password) and AZURE_TENANT_ID (tenant) environment variables . Key concepts Credentials A credential is a class which contains or can obtain the data needed for a service client to authenticate requests. Service clients across Azure SDK accept credentials when they are constructed and use those credentials to authenticate requests to the service. Azure Identity offers a variety of credential classes in the Azure.Identity namespace capable of acquiring an AAD token. All of these credential classes are implementations of the TokenCredential abstract class in Azure.Core , and can be used by any service client which can be constructed with a TokenCredential . The credential types in Azure Identity differ in the types of AAD identities they can authenticate and how they are configured: credential class identity configuration DefaultAzureCredential service principal or managed identity none for managed identity; environment variables for service principal ManagedIdentityCredential managed identity constructor parameters EnvironmentCredential service principal environment variables ClientSecretCredential service principal constructor parameters CertificateCredential service principal constructor parameters Credentials can be chained together to be tried in turn until one succeeds using the ChainedTokenCredential ; see chaining credentials for details. Note : All credential implementations in the Azure Identity library are threadsafe, and a single credential instance can be used to create multiple service clients. DefaultAzureCredential DefaultAzureCredential is appropriate for most scenarios where the application is intended to run in the Azure Cloud. This is because the DefaultAzureCredential determines the appropriate credential type based of the environment it is executing in. It supports authenticating both as a service principal or managed identity, and can be configured so that it will work both in a local development environment or when deployed to the cloud. The DefaultAzureCredential will first attempt to authenticate using credentials provided in the environment. In a development environment you can authenticate as a service principal with the DefaultAzureCredential by providing configuration in environment variables as described in the next section. If the environment configuration is not present or incomplete, the DefaultAzureCredential will then determine if a managed identity is available in the current environment. Authenticating as a managed identity requires no configuration, but does require platform support. See the managed identity documentation for more details on this. Environment variables DefaultAzureCredential and EnvironmentCredential are configured for service principal authentication with these environment variables: variable name value AZURE_CLIENT_ID service principal's app id AZURE_TENANT_ID id of the principal's Azure Active Directory tenant AZURE_CLIENT_SECRET one of the service principal's client secrets Examples Authenticating with DefaultAzureCredential This example demonstrates authenticating the SecretClient from the Azure.Security.KeyVault.Secrets client library using the DefaultAzureCredential . using Azure.Identity; using Azure.Security.KeyVault.Secrets; // Create a secret client using the DefaultAzureCredential var client = new SecretClient(new Uri(\"https://myvault.azure.vaults.net/\"), new DefaultAzureCredential()); When executing this in a development machine you need to first configure the environment setting the variables AZURE_CLIENT_ID , AZURE_TENANT_ID and AZURE_CLIENT_SECRET to the appropriate values for your service principal. Authenticating a service principal with a client secret This example demonstrates authenticating the BlobClient from the Azure.Storage.Blobs client library using the ClientSecretCredential . using Azure.Identity; using Azure.Storage.Blobs; // authenticating a service principal with a client secret var credential = new ClientSecretCredential(tenantId, clientId, clientSecret); var blobClient = new BlobClient(new Uri(\"https://myaccount.blob.core.windows.net/mycontainer/myblob\"), credential); Authenticating a service principal with a certificate This example demonstrates authenticating the KeyClient from the Azure.Security.KeyVault.Keys client library using the CertificateCredential . using Azure.Identity; using Azure.Security.KeyVault.Keys; // authenticating a service principal with a certificate var certificate = new X509Certificate2(\"./app/certs/certificate.pfx\"); var credential = new CertificateCredential(tenantId, clientId, certificate); var keyClient = new KeyClient(new Uri(\"https://myvault.azure.vaults.net/\"), credential); Chaining Credentials The ChainedTokenCredential class provides the ability to link together multiple credential instances to be tried sequentially when authenticating. The following example demonstrates creating a credential which will attempt to authenticate using managed identity, and fall back to certificate authentication if a managed identity is unavailable in the current environment. This example authenticates an EventHubClient from the Azure.Messaging.EventHubs client library using the ChainedTokenCredential . using Azure.Identity; using Azure.Messaging.EventHubs; var managedCredential = new ManagedIdentityCredential(clientId); var certCredential = new CertificateCredential(tenantId, clientId, certificate); // authenticate using managed identity if it is available otherwise use certificate auth var credential = new ChainedTokenCredential(managedCredential, certCredential); var eventHubClient = new EventHubClient(\"myeventhub.eventhubs.windows.net\", \"myhubpath\", credential); Troubleshooting Errors arising from authentication can be raised on any service client method which makes a request to the service. This is because the first time the token is requested from the credential is on the first call to the service, and any subsequent calls might need to refresh the token. In order to distinguish these failures from failures in the service client Azure Identity classes raise the AuthenticationFailedException with details to the source of the error in the exception message as well as possibly the error message. For more details on dealing with errors arising from failed requests to Azure Active Directory, or managed identity endpoints please refer to the Azure Active Directory documentation on authorization error codes . Next steps Currently the following client libraries support authenticating with TokenCredential and the Azure Identity library. You can learn more about their use, and find additional documentation on use of these client libraries along samples with can be found in the links below. Azure.Messaging.EventHubs Azure.Security.KeyVault.Keys Azure.Security.KeyVault.Secrets Azure.Storage.Blobs Azure.Storage.Queues Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.microsoft.com . When you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. <!-- LINKS -->"
  },
  "articles/sdk/Core/Azure.Core/README.html": {
    "href": "articles/sdk/Core/Azure.Core/README.html",
    "title": "Azure.Core shared library for .NET | Azure SDK for Net",
    "keywords": "Azure.Core shared library for .NET Azure.Core provides shared primitives, abstractions, and helpers for modern .NET Azure SDK client libraries. These libraries follow the Azure SDK Design Guidelines for .NET and can be easily identified by package and namespaces names starting with 'Azure', e.g. Azure.Storage.Blobs . A more complete list of client libraries using Azure.Core can be found here . Azure.Core allows client libraries to expose common functionality in a consistent fashion, so that once you learn how to use these APIs in one client library, you will know how to use them in other client libraries. The main shared concepts of Azure.Core (and so Azure SDK libraries using Azure.Core) include: Configuring service clients, e.g. configuring retries, logging. Accessing HTTP response details. Calling long running operations (LROs). Paging and asynchronous streams ( IAsyncEnumerable<T> ) Exceptions for reporting errors from service requests in a consistent fashion. Abstractions for representing Azure SDK credentials. Below, you will find sections explaining these shared concepts in more detail. Installing Typically, you will not need to install Azure.Core; it will be installed for you when you install one of the client libraries using it. In case you want to install it explicitly (to implement your own client library, for example), you can find the NuGet package here . Usage Scenarios and Samples Configuring Service Clients Using ClientOptions Azure SDK client libraries typically expose one or more service client types that are the main starting points for calling corresponding Azure services. You can easily find these client types as their names end with the word Client . For example, BlockBlobClient can be used to call blob storage service, and KeyClient can be used to access KeyVault service cryptographic keys. These client types can be instantiated by calling a simple constructor, or its overload that takes various configuration options. These options are passed as a parameter that extends ClientOptions class exposed by Azure.Core. Various service specific options are usually added to its subclasses, but a set of SDK-wide options are available directly on ClientOptions . public void ConfigureServiceClient() { // BlobConnectionOptions inherits/extends ClientOptions ClientOptions options = new BlobConnectionOptions(); // configure retries options.RetryPolicy.MaxRetries = 5; // default is 3 options.RetryPolicy.Mode = RetryMode.Exponential; // default is fixed retry policy options.RetryPolicy.Delay = TimeSpan.FromSeconds(1); // default is 0.8s // finally create BlobContainerClient, but many Azure SDK clients will work similarly var client = new BlobContainerClient(connectionString, \"container\", options); // if you don't specify the options, default options will be used, e.g. var clientWithDefaultOptions = new BlobContainerClient(connectionString, \"container\"); } Accessing HTTP Response Details Using Response<T> Service clients have methods that can be used to call Azure services. We refer to these client methods service methods . Service methods return a shared Azure.Core type Response<T> (in rare cases its non-generic sibling, a raw Response ). This type provides access to both the deserialized result of the service call, and to the details of the HTTP response returned from the server. public async Task UsingResponseOfT() { // create a client var client = new BlobContainerClient(connectionString, \"container\"); // call a service method, which returns Response<T> Response<ContainerItem> response = await client.GetPropertiesAsync(); // Response<T> has two main accessors. // Value property for accessing the deserialized result of the call ContainerItem container = response.Value; // .. and GetRawResponse method for accessing all the details of the HTTP response Response http = response.GetRawResponse(); // for example, you can access HTTP status int status = http.Status; // or the headers foreach(HttpHeader header = http.Headers) { Console.WriteLine($\"{header.Name} {header.Value}\"); } // or the stream of the response content Stream content = http.ContentStream; // but, if you are not interested in all HTTP details, // and just want the result of the service call, // Response<T> provides a cast to get you directly to the result ContainerItem result = await client.GetPropertiesAsync(); } Mocking One of the most important cross-cutting features of our new client libraries using Azure.Core is that they are designed for mocking. Mocking is enabled by: providing a protected parameterless constructor on client types. making service methods virtual. providing APIs for constructing model types returned from virtual service methods. To find these factory methods look for types with the ModelFactory suffix, e.g. ConfigurationModelFactory . For example, the ConfigurationClient.Get method can be mocked (with Moq ) as follows: // Create a mock response var mockResponse = new Mock<Response>(); // Create a client mock var mock = new Mock<ConfigurationClient>(); // Setup client method mock.Setup(c => c.Get(\"Key\", It.IsAny<string>(), It.IsAny<DateTimeOffset>(), It.IsAny<CancellationToken>())) .Returns(new Response<ConfigurationSetting>(mockResponse.Object, // factory for the model type ConfigurationModelFactory.ConfigurationSetting(\"Key\", \"Value\") ) ); // Use the client mock ConfigurationClient client = mock.Object; ConfigurationSetting setting = client.Get(\"Key\"); Assert.AreEqual(\"Value\", setting.Value); Reporting Errors RequestFailedException Coming soon ... Consuming Service Methods Returning IAsyncEnumerable<T> Coming soon ... Consuming Long Running Operations Using Operation<T> Comming soon ..."
  },
  "articles/sdk/CognitiveServices/Personalizer/src/Readme.html": {
    "href": "articles/sdk/CognitiveServices/Personalizer/src/Readme.html",
    "title": "Microsoft Cognitive Services Personalizer SDK for .NET | Azure SDK for Net",
    "keywords": "Microsoft Cognitive Services Personalizer SDK for .NET This SDK allows you to build applications that consumes Microsoft Cognitive Services Personalizer APIs. APIs For a full list of APIs under Personalizer, please see our list of personalizer APIs . TODO : Update personalizer link Target Frameworks: .NET Framework 4.5.2 Netstandard 1.4, based on the NetCore framework Build Instructions: To build this project, please follow the instructions here ."
  },
  "articles/sdk/CognitiveServices/Personalizer/src/Feedback.html": {
    "href": "articles/sdk/CognitiveServices/Personalizer/src/Feedback.html",
    "title": "Azure Rest API Review Board Core feedback for Microsoft Cognitive Services Personalizer SDK for .NET | Azure SDK for Net",
    "keywords": "Azure Rest API Review Board Core feedback for Microsoft Cognitive Services Personalizer SDK for .NET We received the following feedback from the Azure Rest API Review Board meeting Expose Rank can be exposed at the base path. Limit the length of all string Ids. TimeSpan types should use format : 'duration'. Use enum for rewardAggregation. Use structured error objects for error responses. Use an application Id to scope all API paths to future protect when Apim key auth is replaced by AD auth. Flatten LogProperties model to use StartTime and EndTime. All the above feedback has been addressed in our Personalizer.json update PR - https://github.com/Azure/azure-rest-api-specs/pull/5827 azure-sdk-for-net PR - https://github.com/Azure/azure-sdk-for-net/pull/6033 The above PRs will be merged once we get the final sign-off from Azure Rest API Review Board Core team."
  },
  "articles/sdk/CognitiveServices/Language.TextAnalytics/src/Readme.html": {
    "href": "articles/sdk/CognitiveServices/Language.TextAnalytics/src/Readme.html",
    "title": "Microsoft Cognitive Services Language SDK for .NET | Azure SDK for Net",
    "keywords": "Microsoft Cognitive Services Language SDK for .NET This SDK allows you to build applications that consumes Microsoft Cognitive Services Language APIs. APIs For a full list of APIs under Language, please see our list of language APIs . Target Frameworks: .NET Framework 4.5.2 Netstandard 1.4, based on the NetCore framework Build Instructions: To build this project, please follow the instructions here ."
  },
  "articles/sdk/Batch/Microsoft.Azure.Management.Batch/changelog.html": {
    "href": "articles/sdk/Batch/Microsoft.Azure.Management.Batch/changelog.html",
    "title": "Microsoft.Azure.Management.Batch release notes | Azure SDK for Net",
    "keywords": "Microsoft.Azure.Management.Batch release notes Changes in 8.0.0 REST API version This version targets REST API version 2019-04-01. Features Added BatchAccount properties DedicatedCoreQuotaPerVMFamily and DedicatedCoreQuotaPerVMFamilyEnforced to facilitate the transition to per VM family quota [Breaking] Accounts created with PoolAllocationMode set to UserSubscription will not return core quota properties DedicatedCoreQuota or LowPriorityCoreQuota Changes in 7.0.0 REST API version This version targets REST API version 2018-12-01. Features [Breaking] ResourceFile improvements Added the ability specify an entire Azure Storage container in ResourceFile . A new property HttpUrl replaces BlobSource . This can be any HTTP URL. Previously, this had to be an Azure Blob Storage URL. When constructing a ResourceFile you can now choose from one of the following options: HttpUrl : Specify an HTTP URL pointing to a specific file to download. StorageContainerUrl : Specify an Azure Storage container URL. All blobs matching the BlobPrefix in the Storage container will be downloaded. AutoStorageContainerName : Specify the name of a container in the Batch registered auto-storage account. All blobs matching the BlobPrefix in the Storage container will be downloaded. [Breaking] Removed OSDisk property from VirtualMachineConfiguration . This property is no longer supported. [Breaking] Application no longer has a Packages property, instead the packages can be retrieved via the new ApplicationPackage.List API. [Breaking] TargetOsVersion is now OsVersion , and CurrentOsVersion is no longer supported on CloudServiceConfiguration . Added support on Windows pools for creating users with a specific login mode (either Batch or Interactive ) via WindowsUserConfiguration.LoginMode . Added support for ContainerConfiguration when creating a pool. Bug fixes Deleting an account will no longer return NotFound at the end of the operation Changes in 6.0.0 REST API version This version targets REST API version 2017-09-01. Adding support for Certificate and Pool operations. Changes in 5.1.0 REST API version This version targets REST API version 2017-05-01. Features Added a new CheckNameAvailability API which allows you to check if an account name is available on a particular region. Changes in 5.0.0 REST API version This version targets REST API version 2017-05-01. Features Breaking changes BatchAccount CoreQuota renamed to DedicatedCoreQuota . The structure of CloudError has changed. It now has an Error property, and the error information ( code , message , target , and details ) is inside that property. The type UpdateApplicationParameters was renamed to ApplicationUpdateParameters . The type AddApplicationParameters was renamed to ApplicationCreateParameters . Non-breaking changes BatchAccount now reports the low-priority core quota as well in the property LowPriorityCoreQuota . Added a new Operations API, which can be used to query the available operations. Packaging Now targets netstandard1.4 instead of netstandard1.5 and netstandard1.1 . Changes in 4.2.0 Added option to create a Batch account which allocates pool nodes in the user's subscription. This is done with PoolAllocationMode = UserSubscription . When using this mode, a KeyVaultReference must also be supplied. Changed classes which appear only in responses to be immutable. This version targets REST API version 2017-01-01. Changes in 4.1.0 This package version had an issue and was unlisted on NuGet immediately after shipping. This version should not be used . Changes in 3.0.0 Renamed AccountResource to BatchAccount . Renamed AccountOperations to BatchAccountOperations . The IBatchManagementClient.Account property was also renamed to IBatchManagementClient.BatchAccount . Split Application and ApplicationPackage operations up into two separate operation groups. Updated Application and ApplicationPackage methods to use the standard Create , Delete , Update syntax. For example creating an Application is done via ApplicationOperations.Create . Renamed SubscriptionOperations to LocationOperations and changed SubscriptionOperations.GetSubscriptionQuotas to be LocationOperations.GetQuotas . This version targets REST API version 2015-12-01. Changes in 2.1.0 Added support for .NETStandard. Fixed the .NETFramework 4.5 dependencies. This version targets REST API version 2015-12-01."
  },
  "articles/sdk/Batch/Microsoft.Azure.Batch.Conventions.Files/README.html": {
    "href": "articles/sdk/Batch/Microsoft.Azure.Batch.Conventions.Files/README.html",
    "title": "Azure Batch File Conventions | Azure SDK for Net",
    "keywords": "Azure Batch File Conventions A convention-based library for saving and retrieving Azure Batch task output files. Purpose When you run a task in Azure Batch, the files created by that task are on the compute node where the task ran. As long as the compute node remains up, and within the file retention time of the task, you can retrieve those files via the Batch API. However, if you need the files to remain available even if the compute node is taken down (for example, as part of a pool resize), or after the retention time has expired, you must persist those files to a durable store. This library encapsulates a convention for persisting job and task outputs in Azure blob storage. This allows client code to easily locate the outputs for a given job or task, allowing those outputs to be listed or retrieved by ID and purpose. For example, a client can use the library to request 'list all the intermediate files for task 7' or 'get me the thumbnail preview for job \"mymovie\"' without needing to know names or locations. The categorization of persisted files as 'output', 'preview', etc. is done using the JobOutputKind and TaskOutputKind types. For job output files, the predefined kinds are \"JobOutput\" and \"JobPreview\"; for task output files, \"TaskOutput\", \"TaskPreview\", \"TaskLog\" and \"TaskIntermediate\". You can also define custom kinds if these are useful in your workflow. Prerequisites The library uses the Azure Storage account linked to your Batch account. If your Batch account doesn't have a linked storage account, you can configure one using the Azure portal . Usage The library is intended for use in both task code and client code -- in task code to persist files, in client code to list and retrieve them. Persisting Files in Task Code To persist a file from task code, use the JobOutputStorage and TaskOutputStorage constructors that take a job output container URL, and call the SaveAsync method: var linkedStorageAccount = new CloudStorageAccount(/* credentials */); var jobId = Environment.GetEnvironmentVariable(\"AZ_BATCH_JOB_ID\"); var taskId = Environment.GetEnvironmentVariable(\"AZ_BATCH_TASK_ID\"); var taskOutputStorage = new TaskOutputStorage(linkedStorageAccount, jobId, taskId); await taskOutputStorage.SaveAsync(TaskOutputKind.TaskOutput, \"frame_full_res.jpg\"); await taskOutputStorage.SaveAsync(TaskOutputKind.TaskPreview, \"frame_low_res.jpg\"); Note that all output files from a job, including task outputs, are stored in the same container. This means that storage throttling limits may be enforced if a large number of tasks try to persist files at the same time. Listing and Retrieving Files in Client Code To access persisted files from client code, you must configure the client with the details of the linked storage account. Then use the JobOutputStorage and TaskOutputStorage constructors that take a CloudStorageAccount, or the extension methods on CloudJob and CloudTask. var job = await batchClient.JobOperations.GetJobAsync(jobId); var jobOutputStorage = job.OutputStorage(linkedStorageAccount); var jobOutputBlob = jobOutputStorage.ListOutputs(JobOutputKind.JobOutput) .SingleOrDefault() as CloudBlockBlob; if (jobOutputBlob != null) { await jobOutputBlob.DownloadToFileAsync(\"movie.mp4\", FileMode.Create); } Conventions The conventions library defines paths in Azure blob storage for output storage. All outputs from a job, including task outputs, are stored in a single container. Within that container, outputs are stored by kind and (for task outputs) task ID. This section describes the conventions for the job output container name and for paths within the job output container. Job Output Container Name The job output container name is formed according to the following rules: Normalize the job ID to lower case. (Due to the restricted set of letters permitted in IDs, there are no locale issues with this normalization.) If prepending \"job-\" to the normalized ID gives a valid container name, use that. Otherwise: Calculate the SHA1 hash of the normalized ID, and express it as a 40-character hex string. Replace all underscores, colons, and sequences of one or more hyphens in the normalized ID by single hyphens, then remove any leading or trailing hyphens. If the resulting string is empty, use the string \"job\" instead. If the resulting string is longer than 15 characters, truncate it to 15 characters. If truncation results in a trailing hyphen, remove it. The container name is the string \"job-\", followed by the truncated ID, followed by a hyphen, followed by the hash. For example, if the job ID is MyTerrificJob , then the container name is job-myterrificjob as this is a valid container name. If the job ID is my-_EVEN_MORE_-terrific-job , we cannot use job-my-_even_more_-terrific-job as this is not a valid container name, so we apply the algorithm: The SHA1 hash of my-_even_more_-terrific-job (all lower case) is 68b05a7d8aa6aa65b9a6892c667a6c406a16ad65 . Replacing hyphens and underscores by single hyphens in the lower case ID gives my-even-more-terrific-job . There are no leading or trailing hyphens to remove. Truncating to 15 characters gives us my-even-more-te . Again there are no leading or trailing hyphens to remove. The final container name is job-my-even-more-te-68b05a7d8aa6aa65b9a6892c667a6c406a16ad65 . The purpose behind this algorithm is to ensure that jobs are given valid and unique container names, while preserving human readability as far as possible, by where possible using the job ID, and in other cases including a prefix based on the job ID. Blob Path The blob path within the container depends on whether the output is being stored as a job output or task output. Job outputs are stored as \"${kind}/{filename}\". For example, if the file \"out/mergeresults.txt\" is stored under JobOutputKind.JobOutput, then its path within the container is \"$JobOutput/out/mergeresults.txt\". Task outputs are stored as \"{taskid}/${kind}/{filename}\". For example, if the file \"analytics.log\" from task \"analysis-309\" is stored under TaskOutputKind.TaskLog, then its path within the container is \"analysis-309/$TaskLog/analytics.log\". The purpose behind this structure is to enable clients to readily locate outputs based on their kind - for example, \"list the main outputs of the job\" or \"list the log files for task analysis-309\"."
  },
  "articles/sdk/Batch/Microsoft.Azure.Batch/upcomingchanges.html": {
    "href": "articles/sdk/Batch/Microsoft.Azure.Batch/upcomingchanges.html",
    "title": "Upcoming changes | Azure SDK for Net",
    "keywords": "Upcoming changes These changes are planned but haven't been published yet."
  },
  "articles/sdk/Batch/Microsoft.Azure.Batch/README.html": {
    "href": "articles/sdk/Batch/Microsoft.Azure.Batch/README.html",
    "title": "License notes | Azure SDK for Net",
    "keywords": "License notes The Azure Batch C# client is now under the MIT license. Prior to March 10 2017 it was under the Apache 2.0 license. Azure Batch client developer guide Batch.sln is your one stop shop for all things related to the Azure Batch C# client library. This solution file contains all of the projects affiliated with the Azure Batch client (including testing and tooling). Changing the Azure Batch client Depending on the type of change you want to make, the work required varies. If you follow this process you shouldn't miss anything: Update the Azure Batch Swagger specification, which resides in the Azure/azure-rest-api-specs GitHub repository. Add new entity types into the Swagger specification. Add new APIs as path-verb pairs in the Swagger specification. Add/remove properties on existing entity types in the Swagger specification. Regenerate the src\\GeneratedProtocol folder using the steps below . Update the convenience layer specification file: Tools\\ObjectModelCodeGeneration\\ObjectModelCodeGenerator\\BatchProperties.json . Add new entities that match the Swagger defined entities. Add/remove properties on existing entities as done in the Swagger specification. Regenerate the src\\Generated folder from the convenience layer specification file using the steps below . Add any custom code on the Generated objects into partial classes located in the src directory. You might want to do this to add an [Obsolete] attribute or to add some helper factory methods. If any APIs have changed, or if new APIs have been added, you must update the following places: The src\\IProtocolLayer.cs interface. The src\\ProtocolLayer.cs class. The corresponding operations class, for example PoolOperations.cs . The corresponding entity which the operation is performed on, for example CloudPool.cs . Add tests for your new models and APIs into the correct test projects. Azure.Batch.Unit.Tests for unit tests. These tests do not have any external dependencies (they run entirely in-memory) and are used in the continuous integration job to validate checkins. BatchClientIntegrationTests for integration tests. These tests run against a live Azure Batch endpoint and do not run during CI. Note: You should prefer to add unit tests over integration tests where possible -- integration tests should be reserved for ensuring that the Batch Service accepts the Swagger requests. Testing service behavior should occur in a service test, not the client. The src\\GeneratedProtocol folder The GeneratedProtocol folder holds the code generated by the AutoRest tool from a Swagger specification. In order to regenerate this code, all you need to do is run: RegenerateBatch.cmd <Path to Swagger file> . You can optionally edit the RegenerateBatch.cmd script to point to a newer version of AutoRest if you would like to take advantage of new AutoRest features. The src\\Generated folder This folder contains the convenience layer models for Azure Batch. It is generated from a custom tool. The custom tool reads a specification file located here: Tools\\ObjectModelCodeGeneration\\ObjectModelCodeGenerator\\BatchProperties.json . The convenience layer models require more metadata than the Swagger specification provides, so this file is an extra mapping layer on top of Swagger which provides more detail. Note: The BatchProperties.json specification file just contains the entities; it doesn't have anything related to the actual APIs. New entities defined in the Swagger specification have to be added here as well. See an existing entity for an example. If the type or name of a property has changed in the underlying Swagger specification, it should be updated here as well. There are a number of special flags which have meaning in the BatchProperties.json file. The easiest way to see a list of what flags are supported and at what level is to look at the backing code generation code: For properties: Tools\\ObjectModelCodeGeneration\\CodeGenerationLibrary\\PropertyData.cs For types: Tools\\ObjectModelCodeGeneration\\CodeGenerationLibrary\\ObjectModelTypeData.cs Once BatchProperties.json is updated with your changes, mark the ObjectModelCodeGenerator as your startup project in Visual Studio and run it -- it will regenerate the contents of the src\\Generated folder."
  },
  "articles/sdk/Batch/Microsoft.Azure.Batch/changelog.html": {
    "href": "articles/sdk/Batch/Microsoft.Azure.Batch/changelog.html",
    "title": "Microsoft.Azure.Batch release notes | Azure SDK for Net",
    "keywords": "Microsoft.Azure.Batch release notes Changes in 11.0.0 Features Added maxBackoff parameter to RetryPolicyProvider.ExponentialRetryProvider . This option was already available on the ExponentialRetry constructor, but adding it on RetryPolicyProvider.ExponentialRetryProvider makes it easier to use. [Breaking] Replaced PoolOperations.ListNodeAgentSKUs with PoolOperations.ListSupportedImages . ListSupportedImages contains all of the same information originally available in ListNodeAgentSKUs but in a clearer format. New non-verified images are also now returned. Additional information about Capabilities and BatchSupportEndOfLife is accessible on the ImageInformation object returned by ListSupportedImages . Now support network security rules blocking network access to a CloudPool based on the source port of the traffic. This is done via the SourcePortRanges property on NetworkSecurityGroupRule . When running a container, Batch now supports executing the task in the container working directory or in the Batch task working directory. This is controlled by the WorkingDirectory property on TaskContainerSettings . Bug fixes Improved various confusing or incomplete documentation. REST API version This version of the Batch .NET client library targets version 2019-06-01.9.0 of the Azure Batch REST API. Changes in 10.1.0 Added net461 and netstandard2.0 target frameworks. Updated Microsoft.AspNetCore.WebUtilities to 1.1.2 for the netstandard1.4 target framework. REST API version This version of the Batch .NET client library targets version 2018-12-01.8.0 of the Azure Batch REST API. Changes in 10.0.0 Features [Breaking] Removed support for the ChangeOSVersion API on CloudServiceConfiguration pools. Removed PoolOperations.ChangeOSVersion and PoolOperations.ChangeOSVersionAsync . Renamed TargetOSVersion to OSVersion and removed CurrentOSVersion on CloudPool . Removed PoolState.Upgrading enum. [Breaking] Removed DataEgressGiB and DataIngressGiB from PoolUsageMetrics . These properties are no longer supported. [Breaking] ResourceFile improvements The ResourceFile constructor is now private. Added the ability specify an entire Azure Storage container in ResourceFile . There are now three supported modes for ResourceFile : ResourceFile.FromUrl creates a ResourceFile pointing to a single HTTP URL. ResourceFile.FromStorageContainerUrl creates a ResourceFile pointing to an Azure Blob Storage container. ResourceFile.FromAutoStorageContainer creates a ResourceFile pointing to an Azure Blob Storage container in the Batch registered auto-storage account. URLs provided to ResourceFile via the ResourceFile.FromUrl method can now be any HTTP URL. Previously, these had to be an Azure Blob Storage URL. The BlobPrefix property can be used to filter downloads from a storage container to only those matching the prefix. [Breaking] Removed OSDisk property from VirtualMachineConfiguration . This property is no longer supported. Pools which set the DynamicVNetAssignmentScope on NetworkConfiguration to be DynamicVNetAssignmentScope.Job can now dynamically assign a Virtual Network to each node the job's tasks run on. The specific Virtual Network to join the nodes to is specified in the new JobNetworkConfiguration property on CloudJob and JobSpecification . Note : This feature is in public preview. It is disabled for all Batch accounts except for those which have contacted us and requested to be in the pilot. The maximum lifetime of a task is now 180 days (previously it was 7). Added support on Windows pools for creating users with a specific login mode (either Batch or Interactive ) via WindowsUserConfiguration.LoginMode . The default task retention time for all tasks is now 7 days, previously it was infinite. ExponentialRetry supports a backoff cap, via the MaxBackoff property. Bug fixes The built in retry policies ExponentialRetry and LinearRetry now correctly retry on HTTP status code 429 and honor the retry-after header. REST API version This version of the Batch .NET client library targets version 2018-12-01.8.0 of the Azure Batch REST API. Changes in 9.0.1 Updating Newtonsoft.Json to 10.0.3 REST API version This version of the Batch .NET client library targets version 2018-08-01.7.0 of the Azure Batch REST API. Changes in 9.0.0 Features Added the ability to see what version of the Azure Batch Node Agent is running on each of the VMs in a pool, via the new NodeAgentInformation property on ComputeNode . Added the ability to specify a Filter on the Result of a task. See here for more details. This enables the often requested scenario of performing a server-side query to find all tasks which failed. [Breaking] Added a default retry policy to BatchClient . Note that this policy may not be sufficient for every case. If the old behavior (a BatchClient that doesn't perform any retries) is desired, the default policy can be removed from a BatchClient with client.CustomBehaviors = client.CustomBehaviors.Where(behavior => !(behavior is RetryPolicyProvider)).ToList() . [Breaking] Removed the ValidationStatus property from TaskCounts , as well as the TaskCountValidationStatus enum. [Breaking] The default caching type for DataDisk and OSDisk is now ReadWrite instead of None . Bug fixes Fixed bug when using BatchSharedKeyCredentials where some operations would fail with an Unauthenticated error in netcoreapp2.1 even though the right shared key was used. REST API version This version of the Batch .NET client library targets version 2018-08-01.7.0 of the Azure Batch REST API. Changes in 8.1.2 Rename Nuget package name from Azure.Batch to Microsoft.Azure.Batch Prior to version 8.1.2, this package was named \"Azure.Batch\" on Nuget. The release notes below are for that package. Changes in 8.1.2 Add deprecation announcement to nuget package. Changes in 8.1.1 Bug fixes Fixed bug where LeavingPool state was not correctly returned via the ListPoolNodeCounts method on PoolOperations . Clarified various confusing documentation. REST API version This version of the Batch .NET client library targets version 2018-02-01.6.1 of the Azure Batch REST API. Changes in 8.1.0 Features Added the ability to query pool node counts by state, via the new ListPoolNodeCounts method on PoolOperations . Added the ability to upload Azure Batch node agent logs from a particular node, via the UploadComputeNodeBatchServiceLogs method on PoolOperations and ComputeNode . This is intended for use in debugging by Microsoft support when there are problems on a node. REST API version This version of the Batch .NET client library targets version 2018-02-01.6.1 of the Azure Batch REST API. Import Note The package will be renamed to Microsoft.Azure.Batch in a future release. Changes in 8.0.1 Bug fixes Fixed a bug where deserializing some enum properties could fail if using Newtonsoft 10. REST API version This version of the Batch .NET client library targets version 2017-09-01.6.0 of the Azure Batch REST API. Changes in 8.0.0 Features Added the ability to get a discount on Windows VM pricing if you have on-premises licenses for the OS SKUs you are deploying, via LicenseType on VirtualMachineConfiguration . Added support for attaching empty data drives to VirtualMachineConfiguration based pools, via the new DataDisks property on VirtualMachineConfiguration . [Breaking] Custom images must now be deployed using a reference to an ARM Image, instead of pointing to .vhd files in blobs directly. The new VirtualMachineImageId property on ImageReference contains the reference to the ARM Image, and OSDisk.ImageUris no longer exists. Because of this, ImageReference is now a required property of VirtualMachineConfiguration . [Breaking] Multi-instance tasks (created using MultiInstanceSettings ) must now specify a CoordinationCommandLine , and NumberOfInstances is now optional and defaults to 1. Added support for tasks run using Docker containers. To run a task using a Docker container you must specify a ContainerConfiguration on the VirtualMachineConfiguration for a pool, and then add TaskContainerSettings on the Task. REST API version This version of the Batch .NET client library targets version 2017-09-01.6.0 of the Azure Batch REST API. Changes in 7.1.0 Features Added support for detailed aggregate task counts via a new JobOperations.GetJobTaskCounts API. Also available on CloudJob.GetTaskCounts . Added support for specifying inbound endpoints on pool compute nodes, via a new CloudPool.PoolEndpointConfiguration property. This allows specific ports on the node to be addressed externally. REST API version This version of the Batch .NET client library targets version 2017-06-01.5.1 of the Azure Batch REST API. Changes in 7.0.1 Bug fixes Fixed a bug where requests using HTTP DELETE (for example, DeletePool and DeleteJob ) failed with an authentication error in the netstandard package. This was due to a change made to HttpClient in netcore. This bug impacted the 6.1.0 release as well. REST API version This version of the Batch .NET client library targets version 2017-05-01.5.0 of the Azure Batch REST API. Changes in 7.0.0 License Moved source code and NuGet package from Apache 2.0 license to MIT license. This is more consistent with the other Azure SDKs as well as other open source projects from Microsoft such as .NET. REST API version This version of the Batch .NET client library targets version 2017-05-01.5.0 of the Azure Batch REST API. Features Added support for the new low-priority node type. [Breaking] TargetDedicated and CurrentDedicated on CloudPool and PoolSpecification have been renamed to TargetDedicatedComputeNodes and CurrentDedicatedComputeNodes . [Breaking] ResizeError on CloudPool is now a collection called ResizeErrors . Added a new IsDedicated property on ComputeNode , which is false for low-priority nodes. Added a new AllowLowPriorityNode property to JobManagerTask , which if true allows the JobManagerTask to run on a low-priority compute node. PoolOperations.ResizePool and ResizePoolAsync now take two optional parameters, targetDedicatedComputeNodes and targetLowPriorityComputeNodes , instead of one required parameter targetDedicated . At least one of these two parameters must be specified. Linux user creation improvements [Breaking] Moved SshPrivateKey on UserAccount to a new class LinuxUserConfiguration , which is now a property of UserAccount . Added support for specifying a Uid and Gid when creating a Linux user, also on the new LinuxUserConfiguration class. Added support for uploading task output files to Azure Blob storage. Added support for uploading task output files to persistent storage, via the OutputFiles property on CloudTask and JobManagerTask . Added support for specifying actions to take based on a task's output file upload status, via the FileUploadError property on ExitConditions . Task error reporting improvements [Breaking] Renamed SchedulingError on all ExecutionInfo classes to FailureInformation . FailureInformation is returned any time there is a task failure. This includes all previous scheduling error cases, as well as nonzero task exit codes, and file upload failures from the new output files feature. Added support for determining if a task was a success or a failure via the new Result property on all ExecutionInfo classes. [Breaking] Renamed SchedulingError on ExitConditions to PreProcessingError to more clearly clarify when the error took place in the task life-cycle. [Breaking] Renamed SchedulingErrorCateogry to ErrorCategory . Added support for provisioning application licenses be your pool, via a new ApplicationLicenses property on CloudPool and PoolSpecification . Please note that this feature is in gated public preview, and you must request access to it via a support ticket. Bug fixes [Breaking] Removed Unmapped enum state from AddTaskStatus , CertificateFormat , CertificateVisibility , CertStoreLocation , ComputeNodeFillType , OSType , and PoolLifetimeOption as they were not ever used. Documentation Improved and clarified documentation. Packaging The package now includes a netstandard1.4 assembly instead of the previous netstandard1.5 . Changes in 6.1.0 REST API version This version of the Batch .NET client library targets version 2017-01-01.4.0 of the Azure Batch REST API. Packaging The client library is now supported on .NET Core. The package now includes a netstandard1.5 assembly in addition to the net45 assembly. Changes in 6.0.0 REST API version This version of the Batch .NET client library targets version 2017-01-01.4.0 of the Azure Batch REST API. Features Breaking changes Added support for running a task under a configurable user identity via the UserIdentity property on all task objects ( CloudTask , JobPreparationTask , StartTask , etc). UserIdentity replaces RunElevated . UserIdentity supports running a task as a predefined named user (via UserIdentity.UserName ) or an automatically created user. The AutoUserSpecification specifies an automatically created user account under which to run the task. To translate existing code, change RunElevated = true to UserIdentity = new UserIdentity(new AutoUserSpecification(elevationLevel: ElevationLevel.Admin)) and RunElevated = false to UserIdentity = new UserIdentity(new AutoUserSpecification(elevationLevel: ElevationLevel.NonAdmin)) . Moved FileToStage implementation to the Azure.Batch.FileStaging NuGet package and removed the dependency on WindowsAzure.Storage from the Azure.Batch package. This gives more flexibility on what version of WindowsAzure.Storage to use for users who do not use the FileToStage features. Non-breaking changes Added support for defining pool-wide users, via the UserAccounts property on CloudPool and PoolSpecification . You can run a task as such a user using the UserIdentity constructor that takes a user name. Added support for requesting the Batch service provide an authentication token to the task when it runs. This is done using the AuthenticationTokenSettings on CloudTask and JobManagerTask . This avoids the need to pass Batch account keys to the task in order to issue requests to the Batch service. Added support for specifying an action to take on a task's dependencies if the task fails using the DependencyAction property of ExitOptions . Added support for deploying nodes using custom VHDs, via the OSDisk property of VirtualMachineConfiguration . Note that the Batch account being used must have been created with PoolAllocationMode = UserSubscription to allow this. Added support for Azure Active Directory based authentication. Use BatchClient.Open/OpenAsync(BatchTokenCredentials) to use this form of authentication. This is mandatory for accounts with PoolAllocationMode = UserSubscription . Package dependencies Removed the dependency on WindowsAzure.Storage . Updated to use version 3.3.5 of Microsoft.Rest.ClientRuntime.Azure . Documentation Improved and clarified documentation. Changes in 5.1.2 Bug fixes Fixed a bug where performing JobOperations.GetNodeFile and PoolOperations.GetNodeFile could throw an OutOfMemoryException if the file that was being examined was large. REST API version This version of the Batch .NET client library targets version 2016-07-01.3.1 of the Azure Batch REST API. Changes in 5.1.1 Bug fixes Fixed a bug where certificates with a signing algorithm other than SHA1 were incorrectly imported, causing the Batch service to reject them. REST API version This version of the Batch .NET client library targets version 2016-07-01.3.1 of the Azure Batch REST API. Changes in 5.1.0 Features Added support for a new operation JobOperations.ReactivateTask (or CloudTask.Reactivate ) which allows users to reactivate a previously failed task. REST API version This version of the Batch .NET client library targets version 2016-07-01.3.1 of the Azure Batch REST API. Changes in 5.0.2 Bug fixes Fixed bug where CommitChanges would incorrectly include elements in the request which did not actually change. REST API version This version of the Batch .NET client library targets version 2016-07-01.3.1 of the Azure Batch REST API. Changes in 5.0.1 Bug fixes Fixed bug where CloudJob.Commit and CloudJob.CommitChanges would hit an exception when attempting to commit a job which had previously been gotten using an ODataDetail select clause. Documentation Improved comments for ExitCode on all task execution information objects ( TaskExecutionInformation , JobPreparationTaskExecutionInformation , JobReleaseTaskExecutionInformation , StartTaskInformation , etc) Improved documentation on ocp-range header format. REST API version This version of the Batch .NET client library targets version 2016-07-01.3.1 of the Azure Batch REST API. Changes in 5.0.0 Features Added CommitChanges method on CloudJob , CloudJobSchedule and CloudPool , which use the HTTP PATCH verb to perform partial updates, which can be safer if multiple clients are making concurrent changes). Added support for joining a CloudPool to a virtual network on using the NetworkConfiguration property. Added support for automatically terminating jobs when all tasks complete or when a task fails, via the CloudJob.OnAllTasksComplete and CloudJob.OnAllTasksFailure properties, and the CloudTask.ExitConditions property. Added support for application package references on CloudTask and JobManagerTask . Documentation Improved documentation across various classes in the Microsoft.Azure.Batch namespace as well as the Microsoft.Azure.Batch.Protocol namespaces. Improved documentation for AddTask overload which takes a collection of CloudTask objects to include details about possible exceptions. Improved documentation for the WhenAll / WaitAll methods of TaskStateMonitor . Other Updated constructors for the following types to more clearly convey their required properties: JobManagerTask JobPreparationTask JobReleaseTask JobSpecification StartTask TaskStateMonitor changes: Removed previously Obsolete method WaitAllAsync . Removed WaitAll which returns Task<bool> . Renamed WhenAllAsync to WhenAll . WhenAll overloads now have a consistent return type. Refactored existing methods to provide an overload which takes a CancellationToken , and an overload which takes a timeout. Removed the overload which takes both. REST API version This version of the Batch .NET client library targets version 2016-07-01.3.1 of the Azure Batch REST API. Changes in 4.0.1 Bug fixes Fixed a bug where specifying a DetailLevel on a list operation would fail if the Batch service returned a list spanning multiple pages. Fixed a bug where TaskDependencies and ApplicationPackageSummary could throw a NullReferenceException if the Batch service returned a collection that was null. Fixed a bug where PoolOperations.ListNodeAgentSkus and PoolOperations.ListPoolUsageMetrics were missing support for DetailLevel . Updated FileMode comment to clarify that the default is 0770 instead of 0600 . REST API version This version of the Batch .NET client library targets version 2016-02-01.3.0 of the Azure Batch REST API. Changes in 4.0.0 Package dependencies Removed Hyak.Common dependency. Removed Microsoft.Azure.Common dependency. Added Microsoft.Rest.ClientRuntime.Azure dependency. Updated Azure.Storage 4.x to 6.x. Features Azure Batch now supports Linux compute nodes (you can see which Linux distributions and versions are supported by using the new ListNodeAgentSkus API). New API ListNodeAgentSkus . New API GetRemoteLoginSettings . ResourceFile now has a property FileMode which is used for Linux VM file download. All node file deletion methods now take an optional recursive option (which can be used on directories). Properties can now be read on objects after they have been committed. An exception will be thrown if you attempt to write them though. Refresh() can now be called on objects after they have been added via Commit() . Added a new namespace Microsoft.Azure.Batch.Protocol.BatchRequests which contains types defined for each type of BatchRequest . This is useful for writing interceptors. Changed various properties which had a type of IEnumerable to IReadOnlyList because they are explicitly read-only. Changed CloudJob.CommonEnvironmentSettings type from IEnumerable to IList . Bug fixes Fixed bug where Enable and Disable scheduling APIs weren't correctly inheriting the behaviors of their parent objects. Fixed bug in signing which breaks some requests issued with custom conditional headers such as If-Match. Fixed a few possible memory leaks. Breaking and default behavior changes Changed the default exception thrown from all synchronous methods. Previously, all synchronous methods threw an AggregateException , which usually contained a single inner exception. Now that inner exception will be thrown directly and it will not be wrapped in an outer AggregateException . Changed AddTask(IEnumerable<CloudTask>) to always wrap exceptions from its many parallel REST requests in a ParallelOperationsException . Note that in some cases (such as when performing validation before issuing requests) this method can throw exceptions other than a ParallelOperationsException . The CloudPool class has changed to support the creation and management of Linux pools based on the virtual machine compute infrastructure as well as Windows pools based on the Azure cloud services platform. To configure pools based on Azure cloud services, use the CloudPool.CloudServiceConfiguration property. To configure pools based on the virtual machines infrastructure (specifically Linux pools), use the CloudPool.VirtualMachineConfiguration property. The OSFamily and TargetOSVersion properties are no longer directly on the CloudPool type. These properties apply only to cloud service pools and are now on the CloudServiceConfiguration type. Enumerations Renamed CertificateVisibility.RemoteDesktop to CertificateVisibility.RemoteUser . Renamed CertificateVisibility.Invalid to CertificateVisibility.None . Removed Unmapped state for enumerations which the Batch service guarantees backwards compatibility with. Removed Invalid state from all enums, as this is now represented by the nullability of the enum. Removed ComputeNodeUser constructor. Use the CreateComputeNodeUser method of the ComputeNode or PoolOperations classes instead. Renamed AutoScaleEvaluation class to AutoScaleRun , and removed property DataServiceId . Using a DetailLevel that is not supported by an operation now throws an exception (e.g. trying to use FilterClause on an API that doesn't support it, or trying to use SelectClause on an API that doesn't support it). Renamed AzureError type to BatchError . This should now be accessed on the BatchException via BatchException.RequestInformation.BatchError . Changed AddTaskResult : StatusCode is now Status and is an enum instead of an int. ContentId removed. DataServiceId removed. BatchClient.Open and BatchClient.OpenAsync now take a BatchServiceClient object, not a BatchRestClient object. Made AffinityInformation read-only after construction. Changed TaskSchedulingPolicy.ComputeNodeFillType to be non-nullable. Removed ReadAsStringAsync optional Stream parameter. Refactored the protocol namespace. It is now generated via the AutoRest tool ( https://github.com/Azure/autorest ). Removed the BatchRequest constructor which took a BatchRestClient (it had been marked obsolete since Azure.Batch 3.0.0). Significantly refactored BatchRequest . Changed request interceptor types to reflect changes to BatchRequest . Changed most types in this namespace to comply with the new underlying protocol layer generated by AutoRest. Removed ResourceStatistics.DiskWriteIOps setter. Removed TaskInformation.JobScheduleId property. REST API version This version of the Batch .NET client library targets version 2016-02-01.3.0 of the Azure Batch REST API."
  },
  "articles/Documentation/Versioning.html": {
    "href": "articles/Documentation/Versioning.html",
    "title": "Azure SDK .NET - Versioning | Azure SDK for Net",
    "keywords": "Azure SDK .NET - Versioning This document covers the basic versioning strategy and which properties to use. It is based on the rules outlined in our Azure SDK Releases doc and it closely matches the .NET versioning rules but simplified to only include the parts necessary for our libraries. Package Versioning Package version will look like: MAJOR.MINOR.PATCH-PRERELEASE In the project file use the VersionPrefix property to define the MAJOR.MINOR.PATCH part of the version. <VersionPrefix>1.0.0</VersionPrefix> PRERELEASE will be controlled by: BuildNumber: Should be in the format yyyyMMdd.<build revision> and defaults to today's date yyyyMMdd.1 but can be set by passing in and msbuild property for OfficialBuildId with a matching format. PreReleaseLabel: Defaults to dev but can be set by passing in the msbuild property for PreReleaseVersionLabel . Some examples might be \"preview\", \"preview.1\", etc. VersionKind: Defaults to \"\" which results to the default dev build label but can be set by passing in the msbuild property DotNetFinalVersionKind to one of the values \"\", \"prerelease\", or \"release\". Examples: VersionKind Package version format Example package versions \"\" 1.2.3-<PreReleaseLabel>.<BuildNumber> 1.2.3-dev.20190509.1 \"prerelease\" 1.2.3-<PreReleaseLabel> 1.2.3-preview.1 \"release\" 1.2.3 1.2.3 Assembly Versioning By default the assembly version will be set to the VersionPrefix property but if the assembly version needs to be different for some reason then it can be independently set by the AssemblyVersion property. File Versioning File version has 4 parts and needs to increase every official build. This is especially important when building MSIs. They will use the following format which is also used by the .NET team: FILEMAJOR.FILEMINOR.FILEPATCH.FILEREVISION FILEMAJOR : Specified in the first part of VersionPrefix property. FILEMINOR : Set to MINOR * 100 + PATCH / 100 , where MINOR and PATCH are the 2nd and 3rd parts of VersionPrefix property. FILEPATCH : Set to (PATCH % 100) * 100 + yy . FILEREVISION : Set to (50 * mm + dd) * 100 + r . This algorithm makes it easy to parse the month and date from FILEREVISION while staying in the range of a short which is what a version element uses. The versioning scheme imposes the following limits on these version parts: MAJOR version is in range [0-65535] MINOR version is in range [0-654] PATCH version is in range [0-9999] Build Parameters Parameter Description OfficialBuildId ID of current build. The accepted format is yyyyMMdd.r . Should be passed to build in YAML official build defintion. DotNetFinalVersionKind Specify the kind of version being generated: release , prerelease or empty. PreReleaseVersionLabel Pre-release label to be used on the string. E.g., preview , preview.1 , etc. VersionPrefix Specify the leading part of the version string. If empty it will default to 1.0.0 from the SDK."
  },
  "articles/Documentation/Using-Azure-TestFramework.html": {
    "href": "articles/Documentation/Using-Azure-TestFramework.html",
    "title": "Using Microsoft.Rest.ClientRuntime.Azure.TestFramework | Azure SDK for Net",
    "keywords": "Using Microsoft.Rest.ClientRuntime.Azure.TestFramework Getting Started Accquring TestFramework Setup prior to Record/Playback tests Environment Variables Playback Test Record Test with Interactive login using OrgId Record Test with ServicePrincipal Record/Playback tests Change Test Environment settings at run-time Troubleshooting Supported Key=Value pairs in ConnectionString Environment Variable Reference 2. Accquring TestFramework TestFramework is available on NuGet at https://www.nuget.org/packages/Microsoft.Rest.ClientRuntime.Azure.TestFramework/ . Instructions to manually download it are available on NuGet. However TestFramework will be downloaded automatically as part of the build process, so manually downloading it should generally be unnecessary. 3. Setup prior to Record/Playback of tests In order to Record/Playback a test, you need to setup a connection string that consists various key/value pairs that provides information to the test environment. 3.1 Environment Variables TEST_CSM_ORGID_AUTHENTICATION Value of the env. variable is the connection string that determines how to connect to Azure. This includes authentiation and the Azure environment to connect to. AZURE_TEST_MODE This specifies whether test framework will Record test sessions or Playback previously recorded test sessions. 3.2 Playback Test The default mode is Playback mode, so no setting up of connection string is required. 3.3 Record Test with Interactive login using OrgId This is no longer the preferred option because it only works when running on .NET Framework (Full Desktop version of .NET - 4.5.1+) When running on .NET Core you may get an error like Interactive Login is supported only in NET45 projects . To use interactive login, set the following environment variables before starting Visual Studio: TEST_CSM_ORGID_AUTHENTICATION=SubscriptionId={SubId};AADTenant={tenantId};Environment={env};HttpRecorderMode=Record; AZURE_TEST_MODE=Record 3.4 Record Test with ServicePrincipal This is the preferred option for record because it works with both .NET Framework and .NET Core. To create a service principal, follow the Azure AD guide to create a Application Service Principal . The application type should be Web app / API and the sign-on URL value is irrelevant (you can set any value). After the service principal is created, you will need to give it access to Azure resources. This can be done with the following PowerShell command, with the Service Principal Application ID (this is a guid, not the display name of the service principal) substituted in for {clientId} . New-AzureRmRoleAssignment -ServicePrincipalName {clientId} -RoleDefinitionName Contributor To use this option, set the following environment variable before starting Visual Studio. The following values are substituted into the below connection string: clientId : The Service Principal Application ID clientSecret : A Service Principal Authentication Key tenantId : The AAD Tenant ID TEST_CSM_ORGID_AUTHENTICATION=SubscriptionId={SubId};ServicePrincipal={clientId};ServicePrincipalSecret={clientSecret};AADTenant={tenantId};Environment={env};HttpRecorderMode=Record; AZURE_TEST_MODE=Record 4. Record/Playback Tests Run the test and make sure that you got a generated .json file that matches the test name in the bin folder under *SessionRecords folder Copy SessionRecords folder inside the test project and add all *.json files in Visual Studio setting \"Copy to Output Directory\" property to \"Copy if newer\" To assure that the records work fine, delete the connection string (default mode is Playback mode) OR change HttpRecorderMode within the connection string to \"Playback\" 5. Change Test Environment settings at run-time 1. Once you set your connection string, you can add or update key/value settings Add new key/value pair TestEnvironment.ConnectionString.KeyValuePairs.Add(\"Foo\", \"FooValue\"); Update Existing key/value pair TestEnvironment.ConnectionString.KeyValuePairs[\"keyName\"]=\"new value\" Accessing/Updating TestEndpoints TestEnvironment.Endpoints.GraphUri = new Uri(\"https://newGraphUri.windows.net\"); ###Note:### Changing the above properties at run-time has the potential to hard code few things in your tests. Best practice would be to use these properties to change values at run-time from immediate window at run-time and avoid hard-coding certain values. 6. Troubleshooting Issue: exceptions in Microsoft.Azure.Test.HttpRecorder Ensure that the HttpRecorderMode in the TEST_CSM_ORGID_AUTHENTICATION environment variable is consistent with the value in AZURE_TEST_MODE environment variable. ##7. Connection string 7.1 Supported Key=Value pairs in Connectionstring * ManagementCertificate * SubscriptionId * AADTenant * UserId * Password * ServicePrincipal * ServicePrincipalSecret * Environment={Prod | DogFood | Next | Current | Custom} * RawToken * RawGraphToken * HttpRecorderMode={Record | Playback} * AADAuthEndpoint * OptimizeRecordedFile={true | false:default} true: will trim recorded files when long running operations are detected. * GraphTokenAudienceUri * BaseUri * AADAuthUri * GalleryUri * GraphUri * IbizaPortalUri * RdfePortalUri * ResourceManagementUri * ServiceManagementUri * AADTokenAudienceUri * GraphTokenAudienceUri * DataLakeStoreServiceUri * DataLakeAnalyticsJobAndCatalogServiceUri 8. Supported Environment in Test framework (Azure environments) 8.1 Default Environments and associated Uri Environment = Prod AADAuthUri = \"https://login.microsoftonline.com\" GalleryUri = \"https://gallery.azure.com/\" GraphUri = \"https://graph.windows.net/\" IbizaPortalUri = \"https://portal.azure.com/\" RdfePortalUri = \"http://go.microsoft.com/fwlink/?LinkId=254433\" ResourceManagementUri = \"https://management.azure.com/\" ServiceManagementUri = \"https://management.core.windows.net\" AADTokenAudienceUri = \"https://management.core.windows.net\" GraphTokenAudienceUri = \"https://graph.windows.net/\" DataLakeStoreServiceUri = \"https://azuredatalakestore.net\" DataLakeAnalyticsJobAndCatalogServiceUri = \"https://azuredatalakeanalytics.net\" Environment = Dogfood AADAuthUri = \"https://login.windows-ppe.net\"; GalleryUri = \"https://df.gallery.azure-test.net/\"; GraphUri = \"https://graph.ppe.windows.net/\"; IbizaPortalUri = \"http://df.onecloud.azure-test.net\"; RdfePortalUri = \"https://windows.azure-test.net\"; ResourceManagementUri = \"https://api-dogfood.resources.windows-int.net/\"; ServiceManagementUri = \"https://management-preview.core.windows-int.net\"; AADTokenAudienceUri = \"https://management.core.windows.net\"; GraphTokenAudienceUri = \"https://graph.ppe.windows.net/\"; DataLakeStoreServiceUri = \"https://caboaccountdogfood.net\"; DataLakeAnalyticsJobAndCatalogServiceUri = \"https://konaaccountdogfood.net\"; Environment = Next AADAuthUri = \"https://login.windows-ppe.net\" GalleryUri = \"https://next.gallery.azure-test.net/\" GraphUri = \"https://graph.ppe.windows.net/\" IbizaPortalUri = \"http://next.onecloud.azure-test.net\" RdfePortalUri = \"https://auxnext.windows.azure-test.net\" ResourceManagementUri = \"https://api-next.resources.windows-int.net/\" ServiceManagementUri = \"https://managementnext.rdfetest.dnsdemo4.com\" AADTokenAudienceUri = \"https://management.core.windows.net\" GraphTokenAudienceUri = \"https://graph.ppe.windows.net/\" DataLakeStoreServiceUri = \"https://caboaccountdogfood.net\" DataLakeAnalyticsJobAndCatalogServiceUri = \"https://konaaccountdogfood.net\" Environment = Current AADAuthUri = \"https://login.windows-ppe.net\" GalleryUri = \"https://df.gallery.azure-test.net/\" GraphUri = \"https://graph.ppe.windows.net/\" IbizaPortalUri = \"http://df.onecloud.azure-test.net\" RdfePortalUri = \"https://windows.azure-test.net\" ResourceManagementUri = \"https://api-dogfood.resources.windows-int.net/\" ServiceManagementUri = \"https://management-preview.core.windows-int.net\" AADTokenAudienceUri = \"https://management.core.windows.net\" GraphTokenAudienceUri = \"https://graph.ppe.windows.net/\" DataLakeStoreServiceUri = \"https://caboaccountdogfood.net\" DataLakeAnalyticsJoAbndCatalogServiceUri = \"https://konaaccountdogfood.net\" Environment = Custom When specified, test framework expect all Uri's to be provided by the user as part of the connection string. What is also supported is as below (connections string example) SubscriptionId=subId;Environment=Prod;AADAuthUri=customAuthUri;ResourceManagementUri=CustomResourceMgmtUri Which translates to, all Uri from pre-defined Prod environment will be used, but AADAuthUri and ResourceManagementUri will be overridden by the one provided in the connection string"
  },
  "articles/Documentation/sdk-for-net-packages.html": {
    "href": "articles/Documentation/sdk-for-net-packages.html",
    "title": ".NET SDK Packages | Azure SDK for Net",
    "keywords": ".NET SDK Packages Below are the packages maintained in this repository. Client Libraries Azure Client Library Package Name NuGet Download Batch Microsoft.Azure.Batch Graph.RBAC Microsoft.Azure.Graph.RBAC KeyVault Microsoft.Azure.KeyVault KeyVault Core Microsoft.Azure.KeyVault.Core KeyVault Cryptography Microsoft.Azure.KeyVault.Cryptography KeyVault Extensions Microsoft.Azure.KeyVault.Extensions KeyVault WebKey Microsoft.Azure.KeyVault.WebKey Search Microsoft.Azure.Search Management Libraries Azure Management Library Package Name NuGet Download Analysis Services Microsoft.Azure.Management.Analysis Authorization Microsoft.Azure.Management.Authorization Automation Microsoft.Azure.Management.Automation Batch Microsoft.Azure.Management.Batch Billing Microsoft.Azure.Management.Billing Cdn Microsoft.Azure.Management.Cdn Cognitive Services Microsoft.Azure.Management.CognitiveServices Compute Microsoft.Azure.Management.Compute Consumption Microsoft.Azure.Management.Consumption Container Registry Microsoft.Azure.Management.ContainerRegistry Customer Insights Microsoft.Azure.Management.CustomerInsights Data Lake Analytics Microsoft.Azure.Management.DataLakeAnalytics Data Lake Store Microsoft.Azure.Management.DataLakeStore DeviceProvisioningServices Microsoft.Azure.Management.DeviceProvisioningServices DevTest Labs Microsoft.Azure.Management.DevTestLabs Dns Microsoft.Azure.Management.Dns Event Grid Microsoft.Azure.Management.EventGrid Event Hub Microsoft.Azure.Management.EventHub Insights Microsoft.Azure.Management.Insights Intune Microsoft.Azure.Management.Intune IoT Hub Microsoft.Azure.Management.IotHub Key Vault Microsoft.Azure.Management.KeyVault Logic Microsoft.Azure.Management.Logic Machine Learning Microsoft.Azure.Management.MachineLearning Machine Learning Compute Microsoft.Azure.Management.MachineLearningCompute Media Microsoft.Azure.Management.Media Monitor Microsoft.Azure.Management.Monitor Network Microsoft.Azure.Management.Network Notification Hubs Microsoft.Azure.Management.NotificationHubs Policy Insights Microsoft.Azure.Management.PolicyInsights Operational Insights Microsoft.Azure.Management.OperationalInsights Power BI Embedded Microsoft.Azure.Management.PowerBIEmbedded RecoveryServices Microsoft.Azure.Management.RecoveryServices RecoveryServices.Backup Microsoft.Azure.Management.RecoveryServices.Backup RecoveryServices.SiteRecovery Microsoft.Azure.Management.RecoveryServices.SiteRecovery Redis Cache Microsoft.Azure.Management.RedisCache Relay Microsoft.Azure.Management.Relay Resources Microsoft.Azure.Management.ResourceManager Scheduler Microsoft.Azure.Management.Scheduler Search Microsoft.Azure.Management.Search Security Microsoft.Azure.Management.SecurityCenter Server Management Microsoft.Azure.Management.ServerManagement Service Bus Microsoft.Azure.Management.ServiceBus Service Fabric Microsoft.Azure.Management.ServiceFabric Sql Microsoft.Azure.Management.Sql Storage Microsoft.Azure.Management.Storage StorageSync Microsoft.Azure.Management.StorageSync Stream Analytics Microsoft.Azure.Management.StreamAnalytics Traffic Manager Microsoft.Azure.Management.TrafficManager Websites Microsoft.Azure.Management.Websites Common Libraries Azure Common Library Package Name NuGet Download AppAuthentication Microsoft.Azure.Services.AppAuthentication ClientRuntime Microsoft.Rest.ClientRuntime ClientRuntime.Azure Microsoft.Rest.ClientRuntime.Azure ClientRuntime.Azure.Authentication Microsoft.Rest.ClientRuntime.Azure.Authentication HttpRecorder Microsoft.Azure.Test.HttpRecorder TestFramework Microsoft.Rest.ClientRuntime.Azure.TestFramework Other Libraries Library Package Name NuGet Download Batch File Staging Microsoft.Azure.Batch.FileStaging Batch File Conventions Microsoft.Azure.Batch.Conventions.Files"
  },
  "articles/Documentation/README.html": {
    "href": "articles/Documentation/README.html",
    "title": "Microsoft Azure SDK for .NET Documentation | Azure SDK for Net",
    "keywords": "Microsoft Azure SDK for .NET Documentation The following services have SDKs that are generated from AutoRest ** Old SDKs (as of August 2016) These SDKs depend on Microsoft.Azure.Common Service Name Nuget Package Api Management Microsoft.Azure.Management.ApiManagement Automation Microsoft.WindowsAzure.Management.Automation Azure Backup Microsoft.Azure.Management.BackupServices Azure Stack Microsoft.AzureStack.Management, Microsoft.AzureStack.Management.Storage Commerce Microsoft.Azure.Commerce.UsageAggregates DataFactory Microsoft.Azure.Management.DataFactories DataLake Microsoft.Azure.Management.DataLake.AnalyticsCatalog, Microsoft.Azure.Management.DataLake.AnalyticsJob, Microsoft.Azure.Management.DataLake.StoreFileSystem ExpressRoute Microsoft.WindowsAzure.Management.ExpressRoute HdInsight Microsoft.Azure.Management.HDInsight, Microsoft.Azure.Management.HDInsight.Job Insights Microsoft.Azure.Insights Media Services Microsoft.WindowsAzure.Management.MediaServices Monitor Microsoft.Azure.Monitor Monitoring Microsoft.WindowsAzure.Management.Monitoring Operational Insights Microsoft.Azure.Management.OperationalInsights Recovery Services Microsoft.Azure.Management.RecoveryServices, Microsoft.Azure.Management.RecoveryServices.Backup ServerManagement Microsoft.Azure.Management.ServerManagement Site Recovery Microsoft.Azure.Management.SiteRecovery Sql Microsoft.Azure.Management.Sql, Microsoft.WindowsAzure.Management.Sql Stream Analytics Microsoft.Azure.Management.StreamAnalytics New SDKs (as of August 2016) These SDKs depend on Microsoft.Rest.ClientRuntime.Azure Service Name Nuget Package Authorization Microsoft.Azure.Management.Authorization Batch Microsoft.Azure.Batch Cdn Microsoft.Azure.Management.Cdn Cognitive Services Microsoft.Azure.Management.CognitiveServices Compute Microsoft.Azure.Management.Compute DataLake Analytics Microsoft.Azure.Management.DataLake.Analytics, Microsoft.Azure.Management.DataLake.Store DevTestLabs Microsoft.Azure.Management.DevTestLabs Graph.RBAC Microsoft.Azure.Graph.RBAC Intune Microsoft.Azure.Management.Intune KeyVault Microsoft.Azure.KeyVault, Microsoft.Azure.Management.KeyVault Logic Microsoft.Azure.Management.Logic Machine Learning Microsoft.Azure.Management.MachineLearning Machine Learning Compute Microsoft.Azure.Management.MachineLearningCompute Network Microsoft.Azure.Management.Network NotificationHubs Microsoft.Azure.Management.NotificationHubs Policy Insights Microsoft.Azure.Management.PolicyInsights PowerBI Microsoft.Azure.Management.PowerBIEmbedded Redis Cache Microsoft.Azure.Management.Redis Resource Manager (ARM) Microsoft.Azure.Management.ResourceManager Scheduler Microsoft.Azure.Management.Scheduler Search Microsoft.Azure.Search Storage Microsoft.Azure.Management.Storage Traffic Manager Microsoft.Azure.Management.TrafficManager Websites Microsoft.Azure.Management.WebSites Please see at Azure documentation for more details"
  }
}